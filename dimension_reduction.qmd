# Dimension Reduction

To represent and visualize high-dimensional data in a meaningful way and helps users interpret the data, dimension reduction methods are used to project the data into a lower-dimensional space. Three popular dimension reduction methods are often used: UMAP, PCA, and t-SNE. 

Principal Component Analysis (PCA) is a linear dimension reduction method that projects the data onto the directions of the largest variance. It is fast, deterministic, and easier to interpret (PCA loadings are provided), but it is limited by the linear nature of the projection. For a detailed discussion of PCA, please refer to [this post](https://github.com/skalalab/dimension_reduction/blob/main/pca.ipynb). 

Uniform Manifold Approximation and Projection (UMAP) and t-Distributed Stochastic Neighbor Embedding (t-SNE) are non-linear dimension reduction methods that can capture more complex patterns in the data. They are more flexible and can handle non-linear relationships between features, but they are more computationally expensive, less interpretable, not deterministic (FLIM Playground uses the random seed `42` to ensure reproducibility), and dependent on the hyperparameters. Here is a [post](https://pair-code.github.io/understanding-umap/) that explains how UMAP and t-SNE work at a high level and the meaning of some of the hyperparameters. 

The numerical features are standardized before the dimension reduction. 

## Interface Components

![](analysis_ui_shots/dimension_reduction.png){width=100% fig-align=center}

### Shared Components
- On the left, users can use the [selection widgets](data_analysis.qmd#multivariate-analysis) to select numerical features for the classifier. Multiple features can be selected from each feature group.  
- On the top right, users can use the [filters](data_analysis.qmd#filter-widgets) to subset the data to find the groups of interest. 
- Below the filters, users can select the visual channels using the [visual channels widgets](data_analysis.qmd#visual-channels-widgets) that allows users to `Color by`, `Opacity by`, and `Shape by` categorical features. 
- On the bottom right, users can change the plot style using the [plot styling widgets](data_analysis.qmd#plotting-configuration-widgets). 

### Hyperparameter
Hyperparameters really matter. So we provide a set of interactive widgets to help users to change the hyperparameters and see their effects on the dimension reduction in real time. 

#### UMAP
FLIM Playground uses the `umap-learn` implementation of UMAP. It chooses to expose `n_neighbors` and `min_dist` for users to tweak. Other hyperparameters are set to [default values](https://umap-learn.readthedocs.io/en/latest/parameters.html).

#### t-SNE
FLIM Playground uses the `sklearn.manifold.TSNE` implementation of t-SNE. It chooses to expose `perplexity` and `early_exaggeration` for users to tweak. Other hyperparameters are set to [default values](https://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html).

::: {.columns}
::: {.column width="33%"}
![](analysis_ui_shots/umap.png){width=100%}
:::
::: {.column width="33%"}
![](analysis_ui_shots/pca.png){width=100%}
:::
::: {.column width="33%"}
![](analysis_ui_shots/t_sne.png){width=100%}
:::
:::


