[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "FLIM Playground",
    "section": "",
    "text": "1 Quick Start\nWelcome to the FLIM Playground 🥳🎉🥂! This is an interactive graphical user interface (GUI) that allows you to extract single-cell features from fluorescence lifetime imaging microscopy (FLIM) raw data (Data Extraction) and analyze extracted features or datasets extracted via other methods using a built-in repertoire of methods (Data Analysis).\nTo quickly try out different analysis methods, download this sample dataset and try the online demo. If you prefer to use your own data, read this chapter on data analysis configuration to learn how to configure the system.\nDue to the online demo’s limitation in local file system access, extracting features from raw data is not available in the online demo. Read on to learn more about FLIM Playground from processing raw decay data to gaining insights.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Quick Start</span>"
    ]
  },
  {
    "objectID": "index.html#installation",
    "href": "index.html#installation",
    "title": "FLIM Playground",
    "section": "1.1 Installation",
    "text": "1.1 Installation\nFLIM Playground is built entirely in Python and is open-source.\n\n1.1.1 Download\nDownload the desktop app from GitHub and double-click it to run. Releases are currently available for Windows 11 and Mac OS 26. If your operating system is not either of these, you can build it yourself by following the instructions below. Code will be open-sourced after publication.\n\n\n1.1.2 Build it yourself\n\nClone the repo and navigate into the repository once cloned.\nInstall the Python environment\n\nInstall uv if not yet installed\nrun uv sync\n\nBuild the app\n\nrun pyinstaller Flim-Playground.spec --clean",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Quick Start</span>"
    ]
  },
  {
    "objectID": "index.html#introduction",
    "href": "index.html#introduction",
    "title": "FLIM Playground",
    "section": "1.2 Introduction",
    "text": "1.2 Introduction\nFluorescence lifetime imaging microscopy (FLIM) measures the time it takes for a fluorescent molecule to emit light (return to the ground state) after being excited by a pulse of light (enter excited state). It is sensitive to changes in fluorophore microenvironment including, pH, temperature, and conformational changes due to protein-binding and the presence of quenchers1. Coupled with modern automated cell-segmentation methods2, FLIM enables single-cell analyses that can reveal biological heterogeneity.\n\n\n\n\n\n\nNoteInstrumentation\n\n\n\n\n\nTo acquire FLIM data, a light source—typically a pulsed laser for time-domain methods or a modulated continuous-wave source for frequency-domain methods—is used to excite the fluorophore of interest. The emission is detected using instrumentation capable of resolving fluorescence decay, such as time-correlated single-photon counting (TCSPC), time-gated, or phase/modulation-based detection. In time-domain FLIM, the delay between excitation and photon arrival is measured, and often a histogram is built, with the x-axis representing the delay time and the y-axis representing the number of photons falling into each time bin. Compared to intensity images, FLIM has an additional dimension of time (e.g., 256 time bins per 12.5 nanoseconds).\nIn frequency-domain FLIM, the phase shift and modulation depth of the emission relative to the excitation are determined.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Quick Start</span>"
    ]
  },
  {
    "objectID": "index.html#challenges",
    "href": "index.html#challenges",
    "title": "FLIM Playground",
    "section": "1.3 Challenges",
    "text": "1.3 Challenges\nA diverse set of tools — both open-source and commercial, ranging from libraries to code-free graphical user interfaces (GUIs) — are available to extract and analyze FLIM data, providing alternative methods and therefore flexibility to FLIM researchers. Examples include PhasorPy3, an open-source library for analyzing fluorescence lifetime using the phasor approach; FLUTE4, an open-source GUI for interactive phasor analysis; FLIMPA5, an open-source phasor analysis GUI enabling batch processing, ROI-based quantification, and experiment-level comparison through manual assignment; FLIMLib, an open-source generic curve fitting library that can be used to fit fluorescence lifetime decay data; SPCImage6, a commercial software for fitting and phasor features.\nHowever, while some tools offer code-free interfaces, users still need to write custom code—either to prepare data in the proper format as input, or to further process their outputs for downstream analysis. The fragmentation between tools arises because each focuses on only a subset of data levels: pixel, cell ROI, channel, field of view, and experiment.\n\n1.3.1 Data Levels\n\nPixel:\n\nA single decay curve encoded in vendor-specific file formats (e.g., Becker & Hickl, PicoQuant, etc.)\n\nRegion of Interest (ROI)\n\nMask with cell labels\n\nChannel\n\nDifferent fluorophores\nFluorophore-specific calibration files\nMasks focusing on different parts of the cell (e.g., whole cell, cytoplasm, nucleus, stain, etc.)\nDifferent feature extraction methods (fitting, phasor, morphology, texture)\n\nField of View (FOV)\n\nInput decay types (e.g., 2D, 3/4D, pixel-level lifetime features already fitted)\n\nExperiment\n\nDifferent treatments, time points, cell lines, etc., and combinations thereof\n\n\nAn integrated framework should take into account all data levels ■ ■ ■ ■ ■ (•) while maintaining the flexibility to handle various input types (◦). It should provide a level of abstraction to address fragmentation from data levels and input types.\nAdditionally, the use of FLIM is rapidly evolving, and new methods are being developed all the time. An integrated framework should allow users to choose among alternative methods seamlessly, be the backbone of iterative explorations integral to research, and be ready to incorporate new methods: The provided level of abstraction should address fragmentation from extraction and analysis methods.\nFinally, many of the existing tools especially GUI based softwares are not cross-platform, which limits their accessibility. The Installation addresses this last challenge.\nA closer parallel to FLIM Playground’s integrated approach is the combination of CellProfiler7, which extracts per-object morphological and texture features, and CellProfiler Analyst8, which ingests these outputs or other feature tables for visualization and statistical analysis. However, FLIM Playground stands apart in that it can extract lifetime features from time-resolved data, alongside morphological and texture features from intensity images. Its general data analysis module incorporates FLIM-specific methods (e.g., phasor analysis) and provides statistical models that address additional analysis aspects such as data heterogeneity, in addition to training machine learning classifiers.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Quick Start</span>"
    ]
  },
  {
    "objectID": "index.html#method",
    "href": "index.html#method",
    "title": "FLIM Playground",
    "section": "1.4 Method",
    "text": "1.4 Method\n\n1.4.1 Feature Classes\nTabular data columns can be categorized into three feature classes:\n\nIdentifiers: unique row identifier and (optional) field of view identifier that allow us to investigate the biological heterogeneity at the single-cell level\nCategorical features: conceptually help us group the rows (e.g., treatment will group the rows into different treatment groups)\nNumerical features: quantify the differences/similarities between data groups\n\nScience, from the data perspective, is about closing the conceptual categorical gaps with quantitative measurements.\nAt data levels, the data are processed to extract the feature classes in Data Extraction, and the classes are used in the Data Analysis modules.\n\n\n\n\n\n\n\n1.4.2 Design\nFLIM Playground has two independent sections:\n\n\n\n\n\n\nData Extraction\nData Extraction extracts single-cell features from the raw data. It adopts a framework that offers channel-level flexibility in input types and extraction methods without incurring too much overhead for users. Following the above categorization, it is divided into the following steps:\n\nData Extraction Configuration (A): allows users to choose among alternative input types and extraction methods (extractors).\nMetadata organization (B): extracts the field of view identifiers and their configurations\nNumerical Feature Extraction: extracts single-cell numerical features based on user-selected extractors. More extractors can be integrated in the future.\n\nCalibration (C): calibrate for IRF shift or use fluorescence lifetime standard\nAlternative lifetime extractors (D):\n\nFitting\nPhasor\n\nAlternative intensity-based extractors (D):\n\nMorphology\nTexture\n\n\nCategorical feature extraction (E): extracts single-cell categorical features and combines experiment-level datasets.\n\n\n\nData Analysis\nData Analysis analyzes features—whether extracted through Data Extraction or by other methods—using visualizations and statistical modeling. It deploys a shared framework (F) built to handle the feature classes across all analysis methods, enabling the same interactive and frictionless exploration experience and allowing new methods to be integrated in the future easily.\n\nData Analysis (G) goes in-depth into how FLIM Playground handles the feature classes and Data Analysis Config goes through how users can configure FLIM Playground to analyze datasets that are not extracted by Data Extraction.\n\nHere is the list of analysis methods incorporated into FLIM Playground, grouped by the number of numerical features they take as inputs:\n\nUnivariate analysis\n\nFeature Comparison\nFeature Histogram\nField of View Comparison\n\nBivariate analysis\n\nFeature Distribution\nPhasor Analysis\n\nMultivariate analysis\n\nDimension Reduction\nClassification\n\n\nBoth sections are built in Python and built as self-contained executables ready to run on major operating systems and in browsers (H).\n\n\n\n1.4.3 Summary\nFLIM Playground resolves these challenges with an interactive code-free graphical user interface (GUI) that spans the full pipeline. It integrates validation checks that guide users at every step, and has a built-in repertoire of analytical methods with interactive widgets that encourage hypothesis driven, iterative exploration of large datasets. It is built on a modular architecture that enables incorporation of new algorithms in the future.\n\n\n\n\n1. Datta, R., Heaster, T. M., Sharick, J. T., Gillette, A. A. & Skala, M. C. Fluorescence lifetime imaging microscopy: fundamentals and advances in instrumentation, analysis, and applications. Journal of Biomedical Optics 25, 071203 (2020).\n\n\n2. Stringer, C., Wang, T., Michaelos, M. & Pachitariu, M. Cellpose: A generalist algorithm for cellular segmentation. Nature methods 18, 100–106 (2021).\n\n\n3. Gohlke, C., Pannunzio, B., Schüty, B. & Blanco, R. Phasorpy/phasorpy: v0.7. Zenodo https://doi.org/10.5281/zenodo.16923774 (2025).\n\n\n4. Gottlieb, D., Asadipour, B., Kostina, P., Ung, T. P. L. & Stringari, C. FLUTE: A python GUI for interactive phasor analysis of FLIM data. Biological Imaging 3, e21 (2023).\n\n\n5. Kapsiani, S. et al. FLIMPA: A versatile software for fluorescence lifetime imaging microscopy phasor analysis. Analytical Chemistry (2025).\n\n\n6. Becker, W. The Bh TCSPC Handbook. (Becker & Hickl GmbH, 2021).\n\n\n7. Stirling, D. R. et al. CellProfiler 4: Improvements in speed, utility and usability. BMC Bioinformatics 22, 433 (2021).\n\n\n8. Stirling, D. R., Carpenter, A. E. & Cimini, B. A. CellProfiler analyst 3.0: Accessible data exploration and machine learning for image analysis. Bioinformatics 37, 3992–3994 (2021).",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Quick Start</span>"
    ]
  },
  {
    "objectID": "data_extraction.html",
    "href": "data_extraction.html",
    "title": "2  Overview",
    "section": "",
    "text": "2.1 Stages\nFLIM Playground transforms raw FLIM data into single-cell numerical and categorical features, ensuring smooth integration with downstream analysis. All steps are seamlessly connected through interactive widgets, with built-in error checking and reporting to ensure correctness.\nA high-level overview of the data extraction process is shown below.\nUsers can configure the system once and apply it to future data. After configuration, users can extract features from raw data using the following steps, inspired by the categorization:",
    "crumbs": [
      "Data Extraction",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Overview</span>"
    ]
  },
  {
    "objectID": "data_extraction.html#stages",
    "href": "data_extraction.html#stages",
    "title": "2  Overview",
    "section": "",
    "text": "FOV Metadata Organization (A): each experiment session consists of multiple fields of view (FOVs). This step helps users organize the metadata of the FOVs.\nNumerical feature extraction (B): it calibrates and then extracts single cell numerical features.\n\nCalibration\n\nFit Calibration\nFit Free Calibration\n\nIRF Shift\nFluorescence lifetime standard\n\n\nPer-channel feature extraction includes:\n\nLifetime fitting features: fit an exponential decay curve to the measured decay and extract lifetime features per cell ROI.\nPhasor features: calculate the phasor features such as the phasor coordinates. It also provides phasor analysis.\nMorphology features: calculate morphology features based on the ROI mask.\nTexture features: calculate texture features based on the intensity image and the ROI mask.\n\n\nCategorical feature extraction (C): extract the categorical features such as the treatment, time point, etc based on the FOV name.\n\n\nUsers can then upload the extracted datasets to perform Data Analysis.",
    "crumbs": [
      "Data Extraction",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Overview</span>"
    ]
  },
  {
    "objectID": "data_extraction.html#input-file-types",
    "href": "data_extraction.html#input-file-types",
    "title": "2  Overview",
    "section": "2.2 Input File Types",
    "text": "2.2 Input File Types\n\n2.2.1 Decay\nSee decay types for more details.\n\n2D decay:\n\n.csv: a tabular data sheet with each row representing a cell and each column representing a time bin.\n\n3D/4D decay: besides the spatial dimensions and the time dimension, the extra dimension in the 4D array should be acquisition channels.\n\n.sdt: Becker & Hickl\n.ptu: PicoQuant\n\n\n\n\n2.2.2 Mask\nBecause of the single-cell focus of FLIM Playground, cell-level masks are needed for each channel. Channels can share the same mask, or use different masks (when they use different masks, the mask ID for each cell should match across masks).\nThe cell-level mask can focus on different parts of the cell region, such as the whole cell, the cytoplasm, the nucleus, or the stain part.\nFor an example, see here.\n\n.tiff/.tif: a 2D array with background labeled as 0 and each cell ROI region labeled as a unique positive integer. That integer will be part of the unique cell identifier.\n\n\n\n2.2.3 IRF\nIRF must be a 1D array. Currently, the supported formats are (extendable to more formats in the future):\n\n.txt: it uses np.loadtxt to parse a txt file. It returns a 1D array if the IRF numbers are in one row or in one column.\n\n\n\n2.2.4 SPCImage t1\nIf the decay type is 3D/4D pixel-prefitted, users can provide pixel-prefitted lifetime feature files.\n\n.asc: a 2D array in spatial dimensions outputted by SPCImage, with each (row, column) containing the value of the lifetime feature (e.g. t1: the first component’s lifetime) of that pixel.\nDepending on the chosen number of lifetime components, the other pixel-prefitted feature files are included and their names are inferred from the t1 file, by replacing t1 in the file name with t2, t3, a1[%], etc.\n\n\n\n2.2.5 fluorescence lifetime standard\nIf the fluorescence lifetime standard-based calibration is chosen, users are expected to provide the fluorescence lifetime standard file.\n\n.tiff/.tif: a 3D array, with one dimension representing the time axis.\n\n\n\n2.2.6 Intensity (2D)\nIf the channel’s imaging modality is Intensity-only, users are expected to provide a 2D intensity image in:\n\n.tiff/.tif: a 2D array.",
    "crumbs": [
      "Data Extraction",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Overview</span>"
    ]
  },
  {
    "objectID": "data_extraction.html#limitations",
    "href": "data_extraction.html#limitations",
    "title": "2  Overview",
    "section": "2.3 Limitations",
    "text": "2.3 Limitations\n\nTo simplify the workflow and due to the framework chosen, FLIM Playground does not support pixel-level fitting and fit-free analysis, and there are many other open-source tools that can do so (for a comprehensive list, see here). Instead, it does cell-level fitting and fit-free (phasor) feature extraction by summing up all the decays belonging to the same cell ROI to get one cell-level decay as a preprocessing step1. It also accepts prefitted pixel-level lifetime features from SPCImage and aggregates pixel-level lifetime features to cell-level lifetime features.\n\n\n\n\n\n1. Samimi, K. et al. Segmentation-guided photon pooling enables robust single cell analysis and fast fluorescence lifetime imaging microscopy. bioRxiv https://doi.org/10.1101/2025.09.30.679660 (2025) doi:10.1101/2025.09.30.679660.",
    "crumbs": [
      "Data Extraction",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Overview</span>"
    ]
  },
  {
    "objectID": "data_extraction_config.html",
    "href": "data_extraction_config.html",
    "title": "3  Configuration",
    "section": "",
    "text": "3.1 Cross-Channel Configurations\nConstructing a framework that balances flexibility and usability is about choosing the right abstraction level. FLIM Playground chooses acquisition channel from data levels as the focus and adopt the channel-centric framework. Settings are divided into two categories: cross-channel configurations and per-channel configurations.",
    "crumbs": [
      "Data Extraction",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Configuration</span>"
    ]
  },
  {
    "objectID": "data_extraction_config.html#cross-channel-configurations",
    "href": "data_extraction_config.html#cross-channel-configurations",
    "title": "3  Configuration",
    "section": "",
    "text": "3.1.1 Categorical Features\n\n\n\n\n\nCategorical features are useful to organize the data into groups of interest, and will be used extensively in the Data Analysis module. Users can specify the potential categorical feature names to be extracted in the Categorical Feature Extraction step.\n\n\n3.1.2 Decay Types\nFLIM Playground supports different decay types, including 2D decay, 3D/4D decay, and 3D/4D pixel-prefitted decay, through user specification.\n\n2D Decay\nIn the system developed by Samimi et al.1, single cells flow through and a decay curve is acquired for each cell by aggregating all the photon arrival time delays deemed to be from the same cell. In exchange of spatial distribution, the acquisition speed is increased enormously. The output of the system is a tabular data sheet with each row representing a cell and each column representing a time bin. FLIM Playground currently supports 2D decay in the CSV format.\n\n\n3D/4D Decay\nIn TCSPC-based FLIM, the data is stored in a 3D/4D array and in special format (e.g. .sdt, .ptu). In addition to the spatial dimensions and the time dimension (XYT), the channel dimension may also be present, making it 4 dimensional (CXYT). Some systems can also record a time stack, making it has at most 5 dimensions. FLIM Playground currently supports both .sdt and .ptu files up to 4 dimensions. It reads the duration and the number of time bins from decay file metadata.\n\n\n3D/4D pixel-prefitted\nSince FLIM Playground currently does not support pixel-fitting, users have the option to provide pixel-prefitted outputs from SPCImage in the format of .asc. See here for how FLIM Playground processes SPCImage outputs to obtain cell-level lifetime fitting features.\n\n\n\n3.1.3 Identifiers\n\n\n\n\n\n\nCell Identifier\nUsers can specify the column name for the unique identifier of the cell to be stored in the output dataset. The cell identifier is constructed as {FOV Identifier}_{cell_label}, where the cell_label is the unique integer label in the mask or the row number if the decay type is 2D decay.\n\n\nFOV Identifier\nUsers can specify the column name for the field of view identifier. If the decay type is 2D decay, users may want to specify the column name as exp_name, because the FOV is not image but an experiment.\n\n\n\n3.1.4 Decay Info\n\nLaser frequency\nUsers can specify the laser frequency in GHz. For example, 0.8 GHz equals to 80 MHz. It will be used in the phasor analysis. If you do not intend to use the phasor analysis, you can fill in any number.\n\n\n2D Decay-specific\nSince the 2D decay file does not provide the duration and the number of time bins per laser pulse interval, users need to specify them.\n\n\n\n\n\n\n\n\n3.1.5 Calibration Method\nIt supports two calibration methods for phasor analysis:\n\nIRF shift-based calibration\nfluorescence lifetime standard-based calibration\n\nSince instrumental response function (IRF) or the fluorescence lifetime standard is measured for each channel, they are set in the per-channel configurations. The fluorescence lifetime standard’s lifetime is channel-agnostic.\n\n\n\n\n\n\n\n3.1.6 Number of Channels\nEach FOV is assumed to have the same number of channels. The configuration will dynamically adjust the per-channel configurations based on the specified number of channels. Currently, the maximum number of channels is 4, and it can be extended to house more channels.",
    "crumbs": [
      "Data Extraction",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Configuration</span>"
    ]
  },
  {
    "objectID": "data_extraction_config.html#per-channel-configurations",
    "href": "data_extraction_config.html#per-channel-configurations",
    "title": "3  Configuration",
    "section": "3.2 Per-Channel Configurations",
    "text": "3.2 Per-Channel Configurations\n\n3.2.1 Channel Name\nUsers can customize the channel name based on, for example, the name of the fluorophore.\n\n\n\n\n\n\n\n3.2.2 Imaging Modality\nUsers can specify the imaging modality for each channel. Currently, two modalities are supported:\n\nFLIM: The signal is time resolved, i.e., has a time dimension, and expected to be from one of the decay types.\nIntensity-only: The signal is a spatial map of intensity values (2 spatial dimensions), i.e., has no time dimension. Currently, the only supported signal type is a 2D intensity .tiff/.tif image.\n\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nThis setup allows users to image some channels in FLIM mode, and others in non-FLIM mode. It also allows users to extract and analyze their data if they image in non-FLIM microscopic systems such as epifluorescence, confocal, brightfield, etc. by selecting Intensity-only for all channels.\n\n\n\n\n\n\n\n\nNote\n\n\n\nIf the decay type is 2D decay, the imaging modality for all channels is restricted to FLIM.\n\n\n\n\n3.2.3 Feature Extractor\nFour types of feature extractors are available if the imaging modality is FLIM:\n\nLifetime fit\nLifetime fit free\nIntensity Morphology\nIntensity Texture\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nIf the decay type is 2D decay, the Intensity Morphology and Intensity Texture feature extractors are not applicable.\n\n\nThe Intensity Morphology and Intensity Texture feature extractors are available if the imaging modality is Intensity-only.\n\n\n\n\n\nEach channel can be assigned with its own set of feature extractors. For example, if users do not intend to do lifetime extraction, they can de-select the Lifetime fit and Lifetime fit free options.\n\n\n3.2.4 Number of Components\nIf users select the Lifetime fit under this channel, they can specify the number of components to fit.\n\n\n3.2.5 File Suffix\nThe FOV Metadata Organization step looks for associated input files for all channels of a given FOV using file suffixes. Based on the decay type, calibration method, and the selected feature extractors, the system automatically generates the file suffixes for required input files.\n\n\n\n\n\nIn the example above, channels nadh and fad were asked to provide an IRF file, while channel cd8 did not, because Lifetime fit was selected for the former two channels and not for the latter. The file suffixes of the IRF files were different for each of the two channels, but they shared the same ROI mask file suffix because they used the same ROI mask. The cd8 channel used a different ROI mask than the other two channels, indicated by the mask file suffix.\nFor detailed information on what file formats are supported for each file type (Mask, IRF, etc.), see input file types.\nFor detailed information on how the file suffixes are used, and what each file type (e.g. IRF, Mask, etc.) is, see the FOV Metadata Organization page.",
    "crumbs": [
      "Data Extraction",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Configuration</span>"
    ]
  },
  {
    "objectID": "data_extraction_config.html#save",
    "href": "data_extraction_config.html#save",
    "title": "3  Configuration",
    "section": "3.3 Save",
    "text": "3.3 Save\nFinally, users can save the configuration for future use by clicking the Update Configuration button.\n\n\n\n\n1. Samimi, K. et al. Autofluorescence lifetime flow cytometry with time-correlated single photon counting. Cytometry Part A 105, 607–620 (2024).",
    "crumbs": [
      "Data Extraction",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Configuration</span>"
    ]
  },
  {
    "objectID": "fov_metadata.html",
    "href": "fov_metadata.html",
    "title": "4  Field of View Metadata",
    "section": "",
    "text": "4.1 Metadata\nIt is the first step in the Data Extraction workflow. It organizes the metadata of each field of view (FOV)—including file paths for all required inputs and decay information—into a single metadata file. This file is then used for numerical feature extraction, as well as for users’ own bookkeeping and troubleshooting.\nIt is divided into two sections:\nMetadata are configured earlier in the Data Extraction Configuration step and copied here. Some fields remain editable for flexibility, while others are fixed to ensure usability. Non-editable fields can be modified in the Data Extraction Configuration step. After saving your modifications, return to this page and refresh it to see the changes.",
    "crumbs": [
      "Data Extraction",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Field of View Metadata</span>"
    ]
  },
  {
    "objectID": "fov_metadata.html#metadata",
    "href": "fov_metadata.html#metadata",
    "title": "4  Field of View Metadata",
    "section": "",
    "text": "4.1.1 Decay Type\nSee decay types for more details. The decay type is not editable here.\n\n\n\n\n\n\n\n4.1.2 Channel Names\nSee channel name config for more details. The names are not editable here, though users can choose which channel to include.\n\n\n\n\n\n\n\n4.1.3 Feature Extractors\nSee feature extractor config for more details. The feature extractors for each channel are shown but not editable here.\n\n\n\n\n\n\n\n4.1.4 Decay Info\nSee decay info config for more details. The decay information is editable here.\n\n\n\n\n\n\n2D Decay-specific\nSince the 2D decay file does not provide the duration and the number of time bins per laser pulse interval, users need to specify them.\n\n\n\n\n\n\n\n\n4.1.5 File Suffix\nCopied from the file suffix config. Users can edit the file suffixes here.\n\n\n\n\n\n\n\n4.1.6 fluorescence lifetime standard\nIf the selected fit free calibration method is fluorescence lifetime standard, users are asked to specify the fluorescence lifetime standard file path for each channel and the fluorescence lifetime standard’s lifetime, the default of those are copied from the data extraction configuration.\n\n\n4.1.7 Folder Path\nFinally, users can specify the folder path that contains all the required input files.",
    "crumbs": [
      "Data Extraction",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Field of View Metadata</span>"
    ]
  },
  {
    "objectID": "fov_metadata.html#metadata-extraction",
    "href": "fov_metadata.html#metadata-extraction",
    "title": "4  Field of View Metadata",
    "section": "4.2 Metadata Extraction",
    "text": "4.2 Metadata Extraction\n\n4.2.1 FOV File Paths\nThe first step is to find the fields of view:\n\nit finds all the files recursively in the folder path that ends with the 1st file suffix of the 1st channel.\nthe prefix of all the matched files are considered to be the field of view name.\n\nFOV name = file name - 1st file suffix\n\n\nThen, it uses the found FOV names to find all other files:\n\nfile name to search = FOV name + other file suffixes for each file suffix\n\nThe only exception is the calibration file, because it is not FOV-specific. They will be searched for based on their file suffixes only.\n\nSuccess\n\n\n\n\n\n\n\nMissing\nWhen it cannot find the file based on the file name (FOV name + file suffix for that file type) inside the folder path, it will complain.\n\n\n\n\n\n\n\nDuplicate\nBecause the calibration file is not FOV-specific, it will be searched based on the file suffixes only. If there are multiple files that match the same file suffix, FLIM Playground will be confused as which one to use.\n\n\n\n\n\nFields of view with ✅ are loaded successfully 🎆. FOVs with ❌ (if any) will not be recorded.\n\n\n\n\n\n\nTip\n\n\n\nIf after changing the file names that conform with the prefix assumption, and the problem persists, users can try killing the app and restarting it to clear the cache internally maintained by FLIM Playground.\n\n\n\n\n\n4.2.2 Decay Info\nIf the decay type is 3D/4D decay, FLIM Playground will try to infer the duration and the number of time bins per laser pulse interval from the decay file metadata. It will also check for inconsistencies across all decay files.\n\nChannel Assignment\nIf the decay file associated with the channel found by the previous step is a 4D array, then FLIM Playground will try to infer the channel number for that channel. For each channel name, it will list all non-empty channels as potential channel to be assigned. If there is only one, the assignment is automatic. If there are multiple, users need to select the channel intended. It will also check for inconsistencies across all decay files about their dimensions and complain if there is any.\n\n\nfluorescence lifetime standard\nIf the file path to the fluorescence lifetime standard is specified, FLIM Playground will try to look for and read the file. It expects a tiff or tif file that contains a 3D array, with one of them as the time dimension. It will try to match the time dimension with the time dimension of the decay file. If it cannot find the matching time dimension, it will complain.\n \nOnce the time axis is matched, the file path to the fluorescence lifetime standard, the fluorescence lifetime standard’s lifetime, and the time axis will be recorded.\n\n\n\n4.2.3 Result Preview and Export\nIf there is a non-zero number of FOVs with ✅ and channel assignment and fluorescence lifetime standard checks (if applicable) are passed, a preview of the metadata data sheet will be shown for users to check.\n\n\n\n\n\nAs an example, the following metadata are extracted:\n\nimage_name: The image_name column is the name of each FOV, which is specified in the fov identifier config.\nnadh_Mask, nadh_Decay, nadh_IRF, fad_Mask, fad_Decay, fad_IRF: the file paths of the mask, decay, and IRF files for the nadh and fad channels.\nnadh_input_type, nadh_imaging_modality, fad_input_type, fad_imaging_modality: the decay type for each channel. If they share the same imaging modality, the input types should be the same. The only imaging modality supported by FLIM Playground is FLIM, therefore the input_type for all channels should be from one of the decay types.\nnadh_Lifetime fit free, nadh_Intensity morphology, nadh_Lifetime fit,fad_Intensity morphology, fad_Intensity texture, fad_Lifetime fit: feature extractors for each channel.\nnadh_channel,duration, fad_channel, time_bins, laser_rate: the decay info for each channel and info shared by all channels.\n\nThe user can click the Export FOV Metadata as CSV button to export the metadata to a CSV file.",
    "crumbs": [
      "Data Extraction",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Field of View Metadata</span>"
    ]
  },
  {
    "objectID": "numerical_feature_extraction.html",
    "href": "numerical_feature_extraction.html",
    "title": "5  Numerical Feature Extraction",
    "section": "",
    "text": "5.1 Input\nIn this step, FLIM Playground extracts single-cell numerical features from the raw data in a folder. For each channel, the features to be extracted are specified in the user-selected feature extractors. The available feature extractors are:\nA csv extracted in the fov metadata extraction step that contains the metadata of the FOVs including:\nUsers can either upload a previously extracted metadata file (left), or use the cached metadata file just extracted in the fov metadata extraction step (right).\nFor Lifetime fit and Lifetime fit free feature extractors, the first step is always calibration.",
    "crumbs": [
      "Data Extraction",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Numerical Feature Extraction</span>"
    ]
  },
  {
    "objectID": "numerical_feature_extraction.html#input",
    "href": "numerical_feature_extraction.html#input",
    "title": "5  Numerical Feature Extraction",
    "section": "",
    "text": "required file paths\ndecay type\ndecay info\nselected feature extractors for each channel\nfit free calibration method(if fit free calibration is required)",
    "crumbs": [
      "Data Extraction",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Numerical Feature Extraction</span>"
    ]
  },
  {
    "objectID": "numerical_feature_extraction.html#calibration",
    "href": "numerical_feature_extraction.html#calibration",
    "title": "5  Numerical Feature Extraction",
    "section": "5.2 Calibration",
    "text": "5.2 Calibration\nCalibration in FLIM is essential because raw decays are convolved with the instrument response function (IRF)—the timing profile of the detection system’s response to an ultrashort light pulse that broadens and shifts the measured decay—so without correcting for these, fitted lifetimes and phasor positions are biased and not comparable across days, samples, or instruments.\n\n5.2.1 Fit Calibration\nDuring different experiments, the IRF may shift differently with respect to the measured decay. Before applying reconvolution fitting, the IRF shift needs to be estimated for each channel if the Lifetime fit feature extractor is selected for the channel.\nIt is performed in two steps:\n\nGather the high signal-to-noise ratio (SNR) decay curves\nFor each curve, perform reconvolution fitting and set shift value as the free parameter to be optimized/fitted.\n\nThe distribution of the shift values is displayed as an interactive scatter plot. When clicking on a point, the corresponding decay curve with the fitted curve and the key statistics are displayed for diagnostics. Based on the distribution or using certain prior knowledge, users can specify the shift value applied to all field of views (if Fix the Shift is selected, see fitting options), or use the fov-specific shift value found by the fitting (if Fix the Shift is deselected).\n\n\nGather High SNR Decay Curves\nThe high SNR decay curves are constructed automatically based on the decay type. If it is in 2D format, a total of the brightest 30 curves that are below 100000 photons are selected and evenly distributed across all field of views (one csv file is considered as one FOV). If it is in 3D/4D format, the field of views are images, and one curve is constructed for each image that includes all the non-zero pixels within the ROI mask.\n\n\nReconvolution Fitting\nFitting is essentially an optimization problem: it minimizes the difference between the fitted curve and the measured curve. The fitted curve is modeled by a \\(n^{th}\\) component exponential function convolved with the shifted IRF, and the difference is modeled as an objective metric. Therefore, users are provided with controls over two parts of the fitting process through the fitting options panel:\n\nHow to construct the objective metric\nHow to perform the optimization\n\nImplementation-wise, FLIM Playground uses the lmfit package that takes generic objectives to perform the optimization process that is flexible enough to handle the reconvolution fitting.\nIf at least one channel has Lifetime fit feature extractor selected, the fitting options panel is displayed.\n\n\n\n\n\nLet’s break down the fitting options one by one.\n\nNumber of Components\nThe number \\(n\\) in the \\(n^{th}\\) component exponential function: \\[% Generic (non-normalized) n-exponential decay\nI(\\mathbf{t})=\\sum_{i=1}^{n} A_i\\, e^{-\\mathbf{t}/\\tau_i}, \\qquad \\tau_i&gt;0\n\\]\nTherefore, \\(n\\) determines the parameters to be fitted: the amplitudes \\(A_i\\) and the lifetimes \\(\\tau_i\\). \\(\\mathbf{t}\\) is the time axis of the decay curve calculated by the duration and time bins from the decay info: \\[\\mathbf{t}=\\bigl[0,\\ \\Delta t,\\ 2\\Delta t,\\ \\ldots,\\ (N-1)\\Delta t\\bigr],\n\\quad \\text{where }\\Delta t=\\frac{T}{K}.\n\\]\nIt supports \\(n=1,2,3\\) components.\nAdditionally, the offset is a parameter to be fitted.\n\n\nTime Gates\nDue to the deadtime of the system certain time bins from the head and/or tail of the decay curve are not reliable. The T1 (head) and T2 (tail) gates are used to select the time range of the decay curve to be fitted. Users can inspect the decay curve by clicking the full screen mode button of the plot on the right of the shift result. Hover-based interaction is implemented so users can see the time bin numbers to have a better sense of the time range.\n\n\n\n\n\n\n\n\n\n\nOnly the time bins within the T1 and T2 gates are used to calculate the cost metric.\n\n\nMetric\n\n\n\n\n\nMaximum Likelihood Estimation (MLE): it estimates the parameters by maximizing the likelihood function, which is the probability of the measured data given the model parameters. A mathematically convenient way to do this is to minimize the negative log-likelihood function:\n\\[\n\\text{NLL}(\\theta; t_s,t_e)\n= -\\sum_{k=0}^{N-1} \\mathbf{1}_{[t_s,t_e]}(t_k)\\,\\bigl[y_k \\log m_\\theta(t_k) - m_\\theta(t_k)\\bigr].\n\\]\n\\(\\mathbf{1}_{[t_s,t_e]}\\) is the indicator function that is 1 if \\(t_k\\) is within the time gates\\([t_s, t_e]\\), and 0 otherwise. \\(y_k\\) is the observed count at time \\(t_k\\), and \\(m_\\theta(t_k)\\) is the model prediction at \\(t_k\\).\nLeast Squares (LS): it estimates the parameters by minimizing the sum of the squared differences between the measured curve and the model prediction.\n\n\nFitting Mode\n\n\n\n\n\nAfter constructing the objective metric, the fitting mode is used to determine the optimization algorithm. It is a trade-off between the speed and the effort to avoid local minima.\n\nGlobal: It uses the differential evolution algorithm, a derivative-free, population-based but slow global optimizer.\nLocal: It uses the leastsq (least squares with Levenberg-Marquardt) algorithm if the chosen metric is LS, otherwise it uses the nelder (Nelder-Mead) algorithm.\n\nHybrid: The most time-consuming option but combines the best of both worlds. It uses the differential evolution to find a good initial guess to all the parameters, and then uses the Local to drill in.\n\n\n\n\n\n5.2.2 Fit Free Calibration\nUsers get to choose between the following two methods to calibrate the IRF shift in the configuration step.\n\nShift IRF\nIt is performed similarly to the fit calibration steps, but in the second step, the shift is not optimized (fitted). It shares the same interface as the fit calibration step, where a scatter plot of the shift values is displayed for each channel, only that the plot is not interactive to show the fit. Instead, it outputs the shift that maximizes the cross-correlation between the IRF and each decay. If Fix the Shift is selected, users can specify the shift value that will be applied to all fields of view. Otherwise, the shift value is chosen to be the one that maximizes the cross-correlation between the IRF and the decay.\n\n\n\n\n\n\nNote\n\n\n\nIf both the Lifetime fit and Lifetime fit free feature extractors are selected for this channel, the optimized IRF shift derived from the fit calibration step is reused for the Lifetime fit free feature extractor.\n\n\nIn addition to shifting the IRF based on the chosen shift values, each decay curve is subtracted an offset value and clipped to 0 if the time bin is negative after the subtraction. The offset is chosen to be the mean of the last 10th percentile of the decay curve (tail).\nFinally, the signals of the shifted IRF are deconvolved from the offset-subtracted decay curves using phasor.phasor_divide from the phasorpy package.\n\n\nFluorescence lifetime standard\nBecause the fluorescence lifetime standard is measured in the same system as the decay curves and we know its lifetime, there is no need to account for the IRF shift and the offset. Therefore\nphasorpy’s lifetime.phasor_calibrate function is used to calibrate all the decay curves behind the scene when calculating the phasor coordinates.\n\n\n\n5.2.3 Confirm Calibration\nOnce users are satisfied with the calibration settings (fitting options and shift values), they can click the Confirm Calibration button at the bottom of the page.\n\n\n\n\n\nOnce confirmed, the left panel prompts users to either apply the calibration settings to the downstream extractors or calibrate again. Users can also save the updated settings (fitting options and shift values) to the metadata file.",
    "crumbs": [
      "Data Extraction",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Numerical Feature Extraction</span>"
    ]
  },
  {
    "objectID": "numerical_feature_extraction.html#feature-extraction",
    "href": "numerical_feature_extraction.html#feature-extraction",
    "title": "5  Numerical Feature Extraction",
    "section": "5.3 Feature Extraction",
    "text": "5.3 Feature Extraction\nIf the selected feature extractors do not require IRF shift calibration, or users have finished the calibration, they can proceed to the feature extraction step by clicking the Confirm and Start Analysis button.\nSimilar to the fov metadata extraction step, FLIM Playground extracts the features and displays the extraction status for each field of view.\n\n\n\n\n\nA progress bar is rendered to show the feature extraction progress for each FOV (bottom right).\nWarnings are displayed if cells have NaN values for some features. They are not excluded from the final CSV file.",
    "crumbs": [
      "Data Extraction",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Numerical Feature Extraction</span>"
    ]
  },
  {
    "objectID": "numerical_feature_extraction.html#save-results",
    "href": "numerical_feature_extraction.html#save-results",
    "title": "5  Numerical Feature Extraction",
    "section": "5.4 Save Results",
    "text": "5.4 Save Results\nOnce the feature extraction is finished, users can save the results to a csv file by clicking the Download button at the bottom of the page.",
    "crumbs": [
      "Data Extraction",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Numerical Feature Extraction</span>"
    ]
  },
  {
    "objectID": "lifetime_fit.html",
    "href": "lifetime_fit.html",
    "title": "6  Lifetime Features (Fit)",
    "section": "",
    "text": "6.1 Fitting\nBiological samples often contain mixtures of fluorescent species, each with its own characteristic lifetime. By modeling the decay as a sum of exponentials, the analysis can separate and quantify these different contributions. For example, NADH in cells exists in both free (short lifetime, ~0.4 ns) and protein-bound (longer lifetime, ~2–3 ns) states; by fitting the fluorescence decay with a bi-exponential model, one can estimate the fraction of each state, which provides direct insight into cellular metabolism and energy production pathways.\nFLIM Playground extracts cell-level lifetime fitting features in this feature extractor, including the fraction of each lifetime component (\\(\\alpha_i\\)), their lifetimes (\\(\\tau_i\\)), and mean lifetime (\\(\\tau_{mean}\\)).\n\\[I(t) = \\sum_{i=1}^n A_i \\, e^{-t/\\tau_i}\\]\nIf the decays have not been pre-fitted, FLIM Playground applies the confirmed fitting options (number of components, time gates, metric, and fitting mode) to the same reconvolution fitting process, as described in the irf shift calibration step, with the only difference being that the IRF shift is no longer a free variable to be optimized. To recap, the reconvolution fitting minimizes the difference between the measured curve and the fitted curve modeled by a multi-exponential model convolved with the IRF, quantified by the cost metric.\nOtherwise, FLIM Playground uses the pre-fitted values to calculate the fitting features.\nIn the final dataset, fitting features are prefixed by the combination of the feature extractor name (i.e. Lifetime fit) and the channel name, allowing Data Analysis to group the features. For example, Lifetime fit_nadh: a1 means the fraction of the first lifetime component for the NAD(P)H channel.",
    "crumbs": [
      "Data Extraction",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Lifetime Features (Fit)</span>"
    ]
  },
  {
    "objectID": "lifetime_fit.html#fitting",
    "href": "lifetime_fit.html#fitting",
    "title": "6  Lifetime Features (Fit)",
    "section": "",
    "text": "6.1.1 Preprocessing\nIt sums up all the pixel decays belonging to the same cell ROI labeled by the ROI mask as one decay curve1. The ROI summing reduces variability and bias and allows for short integration times at acquisition in exchange for sub-cellular resolution (i.e., pixel-level). Users do not need to specify the bin factor (each pixel sums up the surrounding pixels’ decay curves) to account for insufficient photon counts. Also, this summing lets a single-threaded CPU app finish in reasonable time\nIt also shifts the IRF using the shift values from the IRF shift calibration step. To shift an IRF, FLIM Playground upsamples the IRF 10 times using linear interpolation to fill the gaps. Then it shifts the IRF by the shift values \\(\\times 10\\) and downsamples the IRF back to the original size.\n\n\n6.1.2 Fraction of components\nIn addition to the absolute amplitudes of each component directly from the fitting result, FLIM Playground calculates the fraction of each component, \\(\\alpha_i\\), as the amplitude of the component divided by the sum of all amplitudes. This normalization allows lifetime to be independent of the absolute intensity of the signal.\n\n\n6.1.3 Mean lifetime\nThe mean lifetime, \\(\\tau_{mean}\\), is calculated as the weighted average of the lifetimes of all components, where the weights are the fractions of each component.\n\\[\\tau_{mean} = \\sum_{i=1}^n \\alpha_i \\tau_i\\]",
    "crumbs": [
      "Data Extraction",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Lifetime Features (Fit)</span>"
    ]
  },
  {
    "objectID": "lifetime_fit.html#pixel-prefitted",
    "href": "lifetime_fit.html#pixel-prefitted",
    "title": "6  Lifetime Features (Fit)",
    "section": "6.2 Pixel-prefitted",
    "text": "6.2 Pixel-prefitted\nCurrently, FLIM Playground supports pixel-prefitted lifetime features from SPCImage. The pixel-level lifetime fitting features are expected to be stored in 2D arrays in spatial dimensions, with each row and column having the value of a lifetime feature outputted from SPCImage. SPCImage assigns 0 for pixels that are not fitted (e.g. thresholded out). To avoid them biasing the results, FLIM Playground uses np.ma.masked_array to create a masked array and disregards them when calculating the averages using np.ma.average.\nThen it uses the ROI mask to calculate the cell-level lifetime features by averaging the pixel-level features within each ROI.\n\n\n\n\n1. Samimi, K. et al. Segmentation-guided photon pooling enables robust single cell analysis and fast fluorescence lifetime imaging microscopy. bioRxiv https://doi.org/10.1101/2025.09.30.679660 (2025) doi:10.1101/2025.09.30.679660.",
    "crumbs": [
      "Data Extraction",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Lifetime Features (Fit)</span>"
    ]
  },
  {
    "objectID": "lifetime_fit_free.html",
    "href": "lifetime_fit_free.html",
    "title": "7  Lifetime Features (Fit-Free)",
    "section": "",
    "text": "7.1 Preprocessing\nPhasor analysis provides a fast, model-free view of lifetimes by transforming fluorescence decays into phasor coordinates through a Fourier transform. This approach is considered “fit-free” because it does not require iterative curve fitting or predefined decay models—each decay is mapped directly to a point on the phasor plot. It has the nice property that mono-exponential decays fall on the universal semicircle while mixtures lie inside as linear combinations, so clusters reveal distinct species and their fractional contributions. FLIM Playground currently extracts cell-level phasor features: g, s, Tau_phase, Tau_m, g_2nd (2nd harmonic), and s_2nd.\nFit-free features in the final dataset are prefixed by the combination of the feature extractor name (i.e. Lifetime fit free) and the channel name, allowing Data Analysis to group the features. For example, Lifetime fit free_nadh: G means the \\(g\\) coordinate for this cell in the NAD(P)H channel.\nIt sums up all the pixel decays belonging to the same cell ROI labeled by the ROI mask as one decay curve1. The phasor features are calculated from the summed decay curve.\nIf the chosen calibration method is IRF shift calibration, FLIM Playground shifts the IRF using the shift values and subtracts the estimated offset as described in the IRF shift calibration step.",
    "crumbs": [
      "Data Extraction",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Lifetime Features (Fit-Free)</span>"
    ]
  },
  {
    "objectID": "lifetime_fit_free.html#phasor-features",
    "href": "lifetime_fit_free.html#phasor-features",
    "title": "7  Lifetime Features (Fit-Free)",
    "section": "7.2 Phasor features",
    "text": "7.2 Phasor features\n\n7.2.1 Step 1: raw phasor coordinates\nThe reference implementation from phasorpy assumes the decay curve comes from one period and time bins are evenly spaced (Untruncated). So their calculation is frequency (\\(f\\)) and time (\\(T\\)) independent. But there are cases when the decay curve is truncated due to the deadtime of the system. For example, when the laser frequency is \\(f = 0.08\\) GHz, the theoretical period is \\(T = 12.5\\) ns, but in practice the time window is truncated to \\(T = 10\\) ns. FLIM Playground applies custom implementation to the truncated decay curve. (the sample_phase option can be used to account for the truncation but it does not handle the second or above harmonics)\n\nUntruncated decay curve\nIt uses the phasor_from_signal function from the phasorpy package to calculate the uncalibrated phasor coordinates g_raw and s_raw, g_raw_2nd and s_raw_2nd, the first and second harmonics’ real and imaginary parts, from the cell decay curve.\nEither g_irf, s_irf, g_irf_2nd, and s_irf_2nd from the IRF, or ref_mean, ref_real, ref_imag from the fluorescence lifetime standard, depending on the chosen calibration method, are calculated using the same function.\nMathematically, the raw phasor coordinates are calculated as (copied from the phasorpy documentation):\n\\[\nF_{\\mathrm{DC}}=\\frac{1}{K}\\sum_{k=0}^{K-1}F_k,\\quad\ng_{\\mathrm{raw}}=\\frac{1}{F_{\\mathrm{DC}}}\\frac{1}{K}\\sum_{k=0}^{K-1}F_k\\cos\\!\\left(2\\pi h \\frac{k}{K}\\right),\\quad\ns_{\\mathrm{raw}}=\\frac{1}{F_{\\mathrm{DC}}}\\frac{1}{K}\\sum_{k=0}^{K-1}F_k\\sin\\!\\left(2\\pi h \\frac{k}{K}\\right)\n\\] where \\(K\\) is the number of time bins, \\(F_k\\) is the decay curve, and \\(h\\) is the harmonic number.\n\n\nTruncated decay curve\nThe phasor coordinates of IRF and the decay curves of both harmonics are calculated using time axis \\(t_k = k\\,(T/K)\\;\\;(k=0,\\ldots,K-1)\\) and angular frequency \\(\\omega = 2\\pi\\,hf\\):\n\\[\ng_{\\mathrm{raw}}\n=\\frac{\\sum_{k=0}^{K-1} F_k \\cos\\!\\big(\\omega\\, t_k\\big)}\n        {\\sum_{k=0}^{K-1} F_k},\\quad\ns_{\\mathrm{raw}}\n=\\frac{\\sum_{k=0}^{K-1} F_k \\sin\\!\\big(\\omega\\, t_k\\big)}\n        {\\sum_{k=0}^{K-1} F_k}\n\\]\nThis formula is equivalent to the untruncated formula when \\(fT = 1\\).\nFor fluorescence lifetime standard, the phasor coordinates are calculated using phasorpy’s phasor_from_signal and sample_phase option is set to \\(\\omega t_k\\).\n\n\n\n7.2.2 Step 2: calibrated phasor coordinates\nTo get the calibrated phasor coordinates g, s, g_2nd, and s_2nd, FLIM Playground uses either\nfrom phasorpy import phasor\ng, s = phasor.phasor_divide(g_raw, s_raw, g_irf, s_irf)\ng_2nd, s_2nd = phasor.phasor_divide(g_raw_2nd, s_raw_2nd, g_irf_2nd, s_irf_2nd)\nor\nfrom phasorpy import lifetime\ng, s = lifetime.phasor_calibrate(g_raw, s_raw, ref_mean, ref_real, ref_imag, frequency=laser_rate, lifetime=reference_dye_lifetime)\ng_2nd, s_2nd = lifetime.phasor_calibrate(g_raw_2nd, s_raw_2nd, ref_mean, ref_real, ref_imag, frequency=laser_rate, lifetime=reference_dye_lifetime, harmonic=2)\nThe laser_rate is specified during the fov metadata extraction and config.\n\n\n7.2.3 Step 3: phasor-derived lifetime\nTau_phase and Tau_m are calculated using the first harmonic’s phasor coordinates g and s.\nimport numpy as np\nw = 2 * np.pi * laser_rate\nphi = np.arctan2(s, g) \nm = np.sqrt(g**2 + s**2)\ntau_phase = 1/w * np.tan(phi)\ntau_m = 1/w * np.sqrt(1/m**2 - 1)\n\\[\n\\phi = \\operatorname{atan2}(s,\\,g), m = \\sqrt{g^{2}+s^{2}}, \\tau_{\\phi} = \\frac{\\tan \\phi}{\\omega}, \\tau_{M} = \\frac{1}{\\omega}\\sqrt{\\frac{1}{m^{2}}-1}\n\\]\n\n\n\n\n1. Samimi, K. et al. Segmentation-guided photon pooling enables robust single cell analysis and fast fluorescence lifetime imaging microscopy. bioRxiv https://doi.org/10.1101/2025.09.30.679660 (2025) doi:10.1101/2025.09.30.679660.",
    "crumbs": [
      "Data Extraction",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Lifetime Features (Fit-Free)</span>"
    ]
  },
  {
    "objectID": "intensity_morphology.html",
    "href": "intensity_morphology.html",
    "title": "8  Morphological Features",
    "section": "",
    "text": "FLIM Playground extracts single-cell morphological features based on the cell region of interest (ROI) mask of each channel. By inputting the ROI mask to skimage.measure.regionprops, the following features are extracted:\n\narea: the number of pixels in the ROI.\nperimeter: length of the ROI boundary in pixels.\nsolidity: \\(\\text{Solidity} = \\frac{\\text{\\# ROI pixels}}{\\text{\\# convex hull pixels}}\\), where the convex hull is the smallest convex polygon that contains the ROI. A value close to 1 means the shape has few concavities (more solid), while lower values indicate more irregular boundaries.\neccentricity: equals to the eccentricity of the ellipse that has the same second moments as the region. It is given by the ratio of the focal distance (the distance between the foci) to the length of the major axis: \\(e = \\frac{c}{a}, \\quad e \\in [0,1)\\), where \\(a\\) is the semi-major axis length, \\(b\\) is the semi-minor axis length, and \\(c = \\sqrt{a^2 - b^2}\\) is the focal distance. When \\(e=0\\), the ellipse reduces to a circle. It quantifies how elongated the ROI is, with 0 being a perfect circle and 1 being a line.\nmajor_axis_length: the length of the major axis of the ellipse that has the same second moments as the region: \\(2a\\). It represents the longest dimension of the ellipse that approximates the region’s shape, essentially describing its maximum elongation.\nminor_axis_length: the length of the minor axis of the ellipse that has the same second moments as the region: \\(2b\\). It represents the shortest dimension of that ellipse, capturing the region’s minimum elongation.\ncircularity: describes how close the ROI is to a perfect circle. It is defined as \\(\\text{circularity} = \\frac{4 \\pi A_{\\text{ROI}}}{P_{\\text{ROI}}^2}, \\quad \\text{circularity} \\in (0,1]\\), where \\(A_{\\text{ROI}}\\) is the area of the region and \\(P_{\\text{ROI}}\\) is its perimeter. A value of \\(1\\) corresponds to a perfect circle.\n\nFeature names in the final dataset are prefixed by the combination of the feature extractor name (i.e. Intensity morphology) and the channel name, allowing Data Analysis to group the features. For example, Intensity morphology_nadh: area means the area of each cell in the NAD(P)H channel.",
    "crumbs": [
      "Data Extraction",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Morphological Features</span>"
    ]
  },
  {
    "objectID": "intensity_texture.html",
    "href": "intensity_texture.html",
    "title": "9  Textural Features",
    "section": "",
    "text": "9.1 Granularity\nFLIM Playground extracts single-cell texture features based on the intensity image and the ROI mask from each acquisition channel. For an example application, refer to this paper which used CellProfiler to extract the texture features.\nThe first step is to create a single cell intensity image for each cell based on the ROI mask and the intensity image. Then a list of texture features (the list may be extended in the future) is calculated:\n\\(Granularity_n\\) is the percentage of intensity removed when bright objects of \\(n\\) pixels in diameter are removed. A disk of radius \\(n\\) is created, and a morphological opening is performed on the single-cell intensity image. The difference between the original and the opened image is the bright objects to be removed. The granularity value, ranging from 0 to 1, is calculated as the ratio of the removed intensity to the total intensity.\n\\(n = 1, 3, 5, 7, 9\\) are calculated.\nSemantically, higher granularity at smaller scales implies higher fragmentation.",
    "crumbs": [
      "Data Extraction",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Textural Features</span>"
    ]
  },
  {
    "objectID": "intensity_texture.html#radial-distribution",
    "href": "intensity_texture.html#radial-distribution",
    "title": "9  Textural Features",
    "section": "9.2 Radial Distribution",
    "text": "9.2 Radial Distribution\nTo calculate the radial distribution, each cell intensity image is partitioned into \\(4\\) concentric rings, and the intensity fraction over the total intensity for each ring is calculated. For example, a higher fraction in ring 1 implies that signals are more concentrated at the center of the cell, whereas a higher fraction in ring 4 implies that signals are more concentrated at the cell edge.",
    "crumbs": [
      "Data Extraction",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Textural Features</span>"
    ]
  },
  {
    "objectID": "intensity_texture.html#mass-displacement",
    "href": "intensity_texture.html#mass-displacement",
    "title": "9  Textural Features",
    "section": "9.3 Mass Displacement",
    "text": "9.3 Mass Displacement\nMass displacement defines the Euclidean distance (in pixels) between the intensity-weighted centroid of the cell ROI and the geometric centroid of the same ROI.",
    "crumbs": [
      "Data Extraction",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Textural Features</span>"
    ]
  },
  {
    "objectID": "intensity_texture.html#intensity-sum",
    "href": "intensity_texture.html#intensity-sum",
    "title": "9  Textural Features",
    "section": "9.4 Intensity Sum",
    "text": "9.4 Intensity Sum\nIntensity sum is defined as the sum of pixel intensities within the cell intensity image.\nIn the final dataset, feature names are prefixed by the combination of the feature extractor name (i.e. Intensity texture) and the channel name, allowing Data Analysis to group the features. For example, Intensity texture_nadh: granularity_1 means the percentage of intensity removed when bright objects of 1-pixel diameter are removed in the NAD(P)H channel.",
    "crumbs": [
      "Data Extraction",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Textural Features</span>"
    ]
  },
  {
    "objectID": "categorical_feature_extraction.html",
    "href": "categorical_feature_extraction.html",
    "title": "10  Categorical Feature Extraction",
    "section": "",
    "text": "10.1 Merging Datasets\nBased on the datasets extracted in the numerical feature extraction step, FLIM Playground:\nIt scans the specified folder path and finds all csv files. It uses the cell identifier column to check for duplicates both within each dataset and across all datasets.\nTherefore, it checks if all field of view names include the same number of segments to determine the eligibility of categorical feature assignment.\nIt merges the datasets that pass the checks by finding common columns and vertically concatenating them.",
    "crumbs": [
      "Data Extraction",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Categorical Feature Extraction</span>"
    ]
  },
  {
    "objectID": "categorical_feature_extraction.html#merging-datasets",
    "href": "categorical_feature_extraction.html#merging-datasets",
    "title": "10  Categorical Feature Extraction",
    "section": "",
    "text": "Important\n\n\n\nThe FOV identifier uniquely identifies a field of view and is assumed to contain all information necessary to extract the categorical features (e.g., treatment, time point, etc.), by including segments separated by a certain delimiter (e.g., _). Categorical features are assigned from individual or combinations of segments.",
    "crumbs": [
      "Data Extraction",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Categorical Feature Extraction</span>"
    ]
  },
  {
    "objectID": "categorical_feature_extraction.html#assigning-categorical-features",
    "href": "categorical_feature_extraction.html#assigning-categorical-features",
    "title": "10  Categorical Feature Extraction",
    "section": "10.2 Assigning Categorical Features",
    "text": "10.2 Assigning Categorical Features\nAvailable categorical features to be assigned are drawn from the user-specified configuration.\n\n\n\n\n\nBased on the assumptions, it breaks down the FOV identifier into individual fields and facilitates the assignment.\n\n\n\n\n\nA live preview of the assignment is displayed.\n\n\n\n\n\nAnd the merged dataset with categorical features is available for download.",
    "crumbs": [
      "Data Extraction",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Categorical Feature Extraction</span>"
    ]
  },
  {
    "objectID": "data_analysis.html",
    "href": "data_analysis.html",
    "title": "11  Overview",
    "section": "",
    "text": "11.1 Methods\nWe are not done yet 😱! FLIM Playground also provides a suite of methods to analyze and visualize the extracted data (either using the Data Extraction module or in users’ own way). They are designed to be interactive and frictionless ⚡ so that users can perform hassle-free exploration of their data with, hopefully, fun 😎. Inspired by the same data categorization as Data Extraction does, the Data Analysis module designs an architectural blueprint that all in-house analysis methods build on. It is modularized so that new methods and features can be added in the future easily.\nAll the methods share a set of interactive widgets to support the general workflow. They also have their own method-specific widgets, the descriptions of which are provided in the corresponding method pages.",
    "crumbs": [
      "Data Analysis",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Overview</span>"
    ]
  },
  {
    "objectID": "data_analysis.html#methods",
    "href": "data_analysis.html#methods",
    "title": "11  Overview",
    "section": "",
    "text": "Depending on the number of numerical features in the analysis, the methods are categorized into 3 groups:\n\nUnivariate Analysis\n\nFeature Comparison\nFeature Histogram\nField of View Comparison\n\nBivariate Analysis\n\n2D Feature Distribution\nPhasor Analysis\n\nMultivariate Analysis\n\nDimension Reduction\nClassification",
    "crumbs": [
      "Data Analysis",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Overview</span>"
    ]
  },
  {
    "objectID": "data_analysis.html#input",
    "href": "data_analysis.html#input",
    "title": "11  Overview",
    "section": "11.2 Input",
    "text": "11.2 Input\nUsers can upload the dataset outputted from the Data Extraction directly or their own datasets in csv (Comma Separated Values) format after finishing the interactive configuration setup.\n\n\n\n\n\n\n\n\n\n\n\n\n11.2.1 Requirements\n\n\n\n\n\n\nImportant\n\n\n\nIn either case, following the categorization, the dataset should have:\n\na column that uniquely identifies each row\nan (optional) field of view identifier column\n\na set of numerical features\nzero or more categorical features (e.g. treatment, day, patient id, etc.)\n\n\n\nThe unique row id and field of view id are used to help users identify the row (e.g. a single cell) and field of view (e.g. a single image) of data of interest through the built-in hover-based interaction. Numerical and categorical features are used to render shared widgets. Internally, FLIM Playground will check whether the dataset fulfills the requirements and output meaningful warning or error messages.\n\n\n\n\n\n\nNote\n\n\n\nWarning messages will not prevent the analysis but error messages will.\n\n\n\n\n11.2.2 Warning Messages\n\nEmpty columns: will be dropped.\nDuplicated columns: Only the first occurrence of the duplicated column will be kept. Other occurrences will be dropped.\nDuplicated rows based on the unique row id: Only the first occurrence of the duplicated row will be kept. Other occurrences will be dropped.\nColumns with NaN values: won’t be dropped, just a warning message.\n\nThe analysis will be performed on the rows that are not NaN in the selected numerical features.\n\n\n\n\n11.2.3 Error Messages\n\nMissing a column that uniquely identifies each row\nCannot identify any numerical feature column\n\nit uses pd.api.types.is_numeric_dtype to check if a column is numerical.",
    "crumbs": [
      "Data Analysis",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Overview</span>"
    ]
  },
  {
    "objectID": "data_analysis.html#shared-interactive-widgets",
    "href": "data_analysis.html#shared-interactive-widgets",
    "title": "11  Overview",
    "section": "11.3 Shared Interactive Widgets",
    "text": "11.3 Shared Interactive Widgets\nA list of shared widgets is provided to support the general workflow in analysis.\n\n11.3.1 General Workflow\n\nselect numerical feature(s) on the left\nsubset the data to find data of interest on the top\nuse visual channels widgets to look at the data in different ways\nchange the plot style\nhover to find data points of interest\n\nThe visualization and analysis results are updated in real time to reflect users’ interactions with any of the above widgets.\n\n\n11.3.2 Numerical Feature Widgets\nThe Data Extraction recognizes numerical features using pd.api.types.is_numeric_dtype internally. Then it groups numerical features based on the feature extractor type and the channel it belongs to. For user-provided datasets, the numerical features are grouped based on the user-specified configuration. Ungrouped numerical features are grouped into a group called Uncategorized Features. One selection widget is rendered for each numerical feature group.\n\n\n\n\n\n\nTip\n\n\n\nIf you cannot find a certain numerical feature under any numerical widgets including Uncategorized Features, please inspect the dataset (e.g., using Excel filters) and look for non-numeric values in that column. One non-numeric value (e.g., “–”) will prevent it from being recognized.\n\n\n\nUnivariate Analysis\nOne set of selection widgets, each can select one feature from a feature group, is rendered. If one feature from a feature group is selected, all the other features groups will be reset to the value Select.\n\n\n\n\n\n\n\nBivariate Analysis\nTwo sets of selection widgets are rendered to allow maximum flexibility (the two features can be from the same or different feature groups). Each set of selection widgets behaves like the selection widgets in the univariate analysis. The first selected feature will be hidden in the second set of selection widgets.\n\n\n\n\n\n\n\nMultivariate Analysis\nOne set of selection widgets, each can select multiple features from a feature group, is rendered. A special value All is introduced so that users can conveniently select all features under the feature group. If users select All, all the other options will be cleared, and vice versa.\n\n\n\n\n\n\n\n\n11.3.3 Categorical Feature Widgets\nFLIM Playground recognizes the categorical features in the uploaded dataset based on the user-specified configuration if the dataset is not extracted by Data Extraction. Otherwise, it recognizes categorical features specified in the Data Extraction configuration.\n\nFilter Widgets\n\nFor complex datasets that are collected over multiple days, experiments, treatments, etc., it is useful to filter the data to focus on a subset of the data (data of interest). One filter widget is rendered for each categorical feature so that users have the flexibility to filter the data based on combinations of categorical features. All is a special option that will include all categories of the selected categorical feature. Once it is selected, all the other options are cleared, and vice versa.\n\n\nVisual Channels Widgets\n\nHuman vision is wired for rapid, parallel pattern and trend detection; good visual encodings (how to map data to visual elements such as color, shape, opacity, etc.) harness this to surface insights that raw numbers or text obscure1. FLIM Playground provides color, opacity, and shape channels for visualizations that support them:\n\nColor by\nColor is supported in all methods except for Classification. In Color by, users can select multiple categorical features, and each unique combination of available categories (determined by the filters in the Filter Widgets) in selected features are assigned a distinct color. Groups created by Color by show up in the x-axis (if multiple features, categories from each feature are delimited by ::).\n\n\n\n\n\n\nNote 11.1: How to order the groups\n\n\n\nThe order of the groups in x-axis and in the legend is determined by:\n\nthe order of the selected features: categories of the first feature appear before those of the second, so on so forth. For example, the two treatments of Panc1 are together, because it is sorted first on the cell lines, then on treatments. If you want the treatments to be together, in Color by you can select treatment then cell_line.\nNumeric-alphabetical sort: within each feature, the category order is determined by the number inside (e.g. 1 in Panc1) first, then the alphabetical order of the category name. Therefore, although P is after M alphabetically, the 1 is before 7 numerically, making Panc1 appears before MCF7. This may be helpful when you have data from different days or hours. The default string sort will put Day 100 before Day 30, and this is not what we want.\n\n\n\n\n\n\n\n\n\n\nOpacity and Shape by\n\nOpacity and shape are supported in all point-based visualizations (e.g. Feature Comparison, 2D Feature Distribution, Phasor Analysis, Dimension Reduction). In Opacity by and Shape by, users can select one categorical feature, and each unique category is assigned a distinct opacity or shape. The order of the shape and opacity is also sorted numer-alphatically.\n\n\n\n\n\n\n\n\n\n\n11.3.4 Unique ID Hover\n\nIn all point-based visualizations, when hovering over a point, the unique id of the point will be shown.\n\n\n\n\n\n\n\n\n11.3.5 Plotting Configuration Widgets\n\nUsers can interactively configure the following plot parameters:\n\npoint size (if point-based)\naxis label size\nlegend size\nthe colormap used to color different groups\n\ncolorblind, tab10, tab20, Set1, Set2, Set3, Pastel1, Pastel2, Accent, viridis, plasma, inferno, magma, cividis\n\n\n\n\n\n\n1. Cleveland, W. S. & McGill, R. Graphical perception: Theory, experimentation, and application to the development of graphical methods. Journal of the American Statistical Association 79, 531–554 (1984).",
    "crumbs": [
      "Data Analysis",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Overview</span>"
    ]
  },
  {
    "objectID": "data_analysis_config.html",
    "href": "data_analysis_config.html",
    "title": "12  Configuration",
    "section": "",
    "text": "12.1 Identifiers Config\nFLIM Playground provides an interactive configuration workflow to help users prepare their datasets that are not extracted by Data Extraction so that they fulfill the requirements. The following sections use the iris dataset, and the flower_id is added to uniquely identify each row (i.e. a single flower). The other columns are: a categorical feature species, and a set of numerical features sepal_length, sepal_width, petal_length, and petal_width.\nOn the left side of the screen, uncheck Use Dataset from Data Extraction.\nThe dataset needs to have a unique identifier column to identify each row. In this case, flower_id is the unique identifier column. This dataset does not have a field of view column, so we leave it blank.",
    "crumbs": [
      "Data Analysis",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Configuration</span>"
    ]
  },
  {
    "objectID": "data_analysis_config.html#categorical-feature-config",
    "href": "data_analysis_config.html#categorical-feature-config",
    "title": "12  Configuration",
    "section": "12.2 Categorical Feature Config",
    "text": "12.2 Categorical Feature Config\nAdd categorical columns you want FLIM Playground to recognize here. Those columns are converted to strings internally.\n\nThe default categorical feature list does not include species, so we add it manually.",
    "crumbs": [
      "Data Analysis",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Configuration</span>"
    ]
  },
  {
    "objectID": "data_analysis_config.html#numerical-feature-config",
    "href": "data_analysis_config.html#numerical-feature-config",
    "title": "12  Configuration",
    "section": "12.3 Numerical Feature Config",
    "text": "12.3 Numerical Feature Config\n\nUsers can copy the numerical features from Excel or any text editor that opens their csv files. The features can be separated by ,, ;, or whitespaces including newlines.\nAfter hitting the ctrl/cmd + enter key, the numerical features are parsed and added to Available Features. Users can add/delete groups and drag features from the Available Features to groups just created. Any ungrouped features are added to a group called Uncategorized Features.\n\n12.3.1 Example",
    "crumbs": [
      "Data Analysis",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Configuration</span>"
    ]
  },
  {
    "objectID": "data_analysis_config.html#save",
    "href": "data_analysis_config.html#save",
    "title": "12  Configuration",
    "section": "12.4 Save",
    "text": "12.4 Save\nAfter users finish the configuration and click the Save Configuration button, FLIM Playground saves the configuration for processing current and future datasets.",
    "crumbs": [
      "Data Analysis",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Configuration</span>"
    ]
  },
  {
    "objectID": "data_analysis_config.html#reset",
    "href": "data_analysis_config.html#reset",
    "title": "12  Configuration",
    "section": "12.5 Reset",
    "text": "12.5 Reset\nUsers can reset the configuration to the default settings.",
    "crumbs": [
      "Data Analysis",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Configuration</span>"
    ]
  },
  {
    "objectID": "feature_comparison.html",
    "href": "feature_comparison.html",
    "title": "13  Feature Comparison",
    "section": "",
    "text": "13.1 Shared Interface Components\nThis method allows users to compare the distributions of a single numerical feature across groups. It can help users spot overarching trends between distributions, identify within distribution shape-related characteristics such as skewness or bimodality that might signal sub-populations, and diagnose for potential outliers.",
    "crumbs": [
      "Univariate Analysis",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Feature Comparison</span>"
    ]
  },
  {
    "objectID": "feature_comparison.html#shared-interface-components",
    "href": "feature_comparison.html#shared-interface-components",
    "title": "13  Feature Comparison",
    "section": "",
    "text": "On the left, users can use the selection widgets to select the numerical feature to be compared. Exactly one feature can be selected from all feature groups.\nOn the top right, users can use the filters to subset the data to find the groups of interest.\nBelow the filters, users can apply the visual channels widgets that allow users to Color by, Opacity by, and Shape by categorical features.\nOn the bottom right, users can change the plot style using the plot styling widgets.",
    "crumbs": [
      "Univariate Analysis",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Feature Comparison</span>"
    ]
  },
  {
    "objectID": "feature_comparison.html#separate-by",
    "href": "feature_comparison.html#separate-by",
    "title": "13  Feature Comparison",
    "section": "13.2 Separate by",
    "text": "13.2 Separate by\n\nSeparate by takes effect before Color by. Separate by divides the plot into sections separated by a dashed line, with each section labeled by one of the available categories of the selected categorical feature after filtering. The selected feature of Separate by is automatically removed from available features in Color by. The section order is determined by the order of the categories which are sorted numeric-alphabetically.\nThen, visual channels (color, shape, opacity) and effect size annotation are applied within each section. For example, the visualization below was separated by cell_line, with each section labelled by the bold text of a cell line. Within each section, the x-axis rendered the Color by categories (treatments) so colors were consistent across sections. Effect size calculation and annotation (only effect size \\(&gt; 0.5\\) is shown) were performed within each section.\n\nIf Separate by is left blank and both cell_line and treatment are selected in Color by, then colors are assigned to each cell line and treatment combination, and effect sizes are calculated across all combinations of group pairs (only pairs with effect size \\(&gt; 0.5\\) are shown).",
    "crumbs": [
      "Univariate Analysis",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Feature Comparison</span>"
    ]
  },
  {
    "objectID": "feature_comparison.html#comparison-widget",
    "href": "feature_comparison.html#comparison-widget",
    "title": "13  Feature Comparison",
    "section": "13.3 Comparison Widget",
    "text": "13.3 Comparison Widget\nStatistical tests and effect size calculations are performed on the selected comparison pairs. FLIM Playground uses the groups on the x-axis populated by Color by to create comparison groups, starting from the leftmost group. For example, if there are 5 groups, then \\(\\binom{5}{2} = 10\\) comparisons will be created. The number of groups can get combinatorially large and many of the comparisons are not meaningful. Therefore, two widgets are provided to filter the comparison groups:\n\nA selection widget that shows all possible comparisons by default and users can deselect groups they do not need.\n\n\n\n\n\n\n\nA threshold by effect size widget that filters out comparisons below the threshold.",
    "crumbs": [
      "Univariate Analysis",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Feature Comparison</span>"
    ]
  },
  {
    "objectID": "feature_comparison.html#effect-size",
    "href": "feature_comparison.html#effect-size",
    "title": "13  Feature Comparison",
    "section": "13.4 Effect Size",
    "text": "13.4 Effect Size\nComplementary to statistical tests, which address “is there a difference?”, effect size metrics answer “how large is the difference?”, enabling cross-study comparison. FLIM Playground offers two effect size calculation methods, Glass’s Delta and Cohen’s d, each can be in mean or median form.\n\n\n\n\n\n\n13.4.1 Glass’s Delta\nMean (\\(\\bar{X}\\)) form: \\[\n\\Delta_G\n  = \\frac{\\bar{X}_{\\text{treatment}} - \\bar{X}_{\\text{control}}}\n         {s_{\\text{control}}},\\qquad\ns_{\\text{control}}\n  = \\sqrt{\\frac{1}{\\,n_c-1\\,}\\sum_{i=1}^{n_c}\n           \\bigl(X_{ci}-\\bar{X}_{\\text{control}}\\bigr)^{2}}\n\\]\nMedian (\\(\\tilde{X}\\)) form: \\[\n\\widetilde{\\Delta}_G\n  = \\frac{\\tilde{X}_{\\text{treatment}} - \\tilde{X}_{\\text{control}}}\n         {\\operatorname{MAD}_{\\text{control}}},\\qquad\n\\operatorname{MAD}_{\\text{control}}\n  = 1.4826 \\times\n    \\operatorname{median}\\!\\bigl\\lvert\n      X_{ci}-\\tilde{X}_{\\text{control}}\n    \\bigr\\rvert\n\\]\n\n\n\n\n\n\nNote\n\n\n\n\\(\\operatorname{MAD}\\) stands for median absolute deviation, a robust measure of the variability of a univariate sample. In order to make \\(\\operatorname{MAD}\\) asymptotically consistent with the standard deviation under normality, it uses \\(C = 1 / \\Phi^{-1}(0.75) \\approx 1.4826\\). Implementation-wise, it uses median_abs_deviation from scipy.stats, and scale option is set to \"normal\" to account for the constant multiplier \\(C\\).\n\n\n\n\n\n\n\n\nImportant\n\n\n\nWho is treatment and who is control matters! From the formula of \\(\\Delta_G\\), switching the order not only flips the sign of the result, but also changes the denominator, which is \\({s_{\\text{control}}}\\), the standard deviation of the control. Currently, FLIM Playground treats the group on the left as treatment and the group on the right as control (the negative \\(\\Delta_G\\) below implies this). In the future, it may support user-customizable x-axis order so that users can arrange the groups to make sure the treatment group is on the left. Or users can use Cohen’s d that does not assume the treatment-control structure.\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nTo keep the point-based visualization style that supports interactive hover while showing the violin plot like distribution, Sina plot is used: it uses gaussian_kde from scikit-learn to make sure the width of the point distribution is proportional to the kernel density.\n\n\n\n\n13.4.2 Cohen’s d\nMean (\\(\\bar{X}\\)) form:\n\\[\nd\n  = \\frac{\\bar{X}_{1}-\\bar{X}_{2}}\n         {s_p},\\qquad\ns_p\n  = \\sqrt{\\frac{(n_1-1)s_1^{2} + (n_2-1)s_2^{2}}\n                 {n_1 + n_2 - 2}}\n\\]\nMedian (\\(\\tilde{X}\\)) form:\n\\[\n\\tilde{d}\n  = \\frac{\\tilde{X}_{1}-\\tilde{X}_{2}}\n         {s_{\\tilde{p}}},\\qquad\ns_{\\tilde{p}}\n  = \\sqrt{\\frac{(n_1-1)\\operatorname{MAD}_{1}^{2}\n             + (n_2-1)\\operatorname{MAD}_{2}^{2}}\n                 {n_1 + n_2 - 2}}\n\\]",
    "crumbs": [
      "Univariate Analysis",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Feature Comparison</span>"
    ]
  },
  {
    "objectID": "feature_comparison.html#statistical-test",
    "href": "feature_comparison.html#statistical-test",
    "title": "13  Feature Comparison",
    "section": "13.5 Statistical Test",
    "text": "13.5 Statistical Test\nStatistical tests are performed on the selected comparison pairs that exceed the effect size threshold (if users choose to calculate effect sizes). The statistical tests supported are:\n\nIndependent t-test (student’s t-test, for equal variances)\nWelch’s t-test (for unequal variances)\n\n\n\n\n\n\nFLIM Playground uses scipy.stats.ttest_ind to perform the independent t-test and scipy.stats.ttest_ind with equal_var=False to perform the Welch’s t-test.",
    "crumbs": [
      "Univariate Analysis",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Feature Comparison</span>"
    ]
  },
  {
    "objectID": "feature_comparison.html#comparison-annotation",
    "href": "feature_comparison.html#comparison-annotation",
    "title": "13  Feature Comparison",
    "section": "13.6 Comparison Annotation",
    "text": "13.6 Comparison Annotation\nFor each selected comparison pair that exceeds the effect size threshold (if any), the statistical significance, effect size, or both are annotated on the plot. It selects the lowest eligible position (over all points in both groups and over existing annotations) to annotate. If both statistical significance and effect size calculation are performed, the annoatation is shown in the format of effect size followed by p-value. If only one is performed, then only the performed method’s result is shown.",
    "crumbs": [
      "Univariate Analysis",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Feature Comparison</span>"
    ]
  },
  {
    "objectID": "feature_histogram.html",
    "href": "feature_histogram.html",
    "title": "14  Feature Histogram",
    "section": "",
    "text": "14.1 Shared Interface Components\nFeature histograms give an instant read-out of each group’s center, spread, skew and any multi-peaked shape that raw tables hide. FLIM Playground plots a histogram for each group based on the selected numerical feature. Additionally, the Gaussian Mixture Model mode can help find subcomponents of each histogram in an unsupervised way. To quantify the distribution heterogeneity, normalized H-index is calculated for each group.",
    "crumbs": [
      "Univariate Analysis",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Feature Histogram</span>"
    ]
  },
  {
    "objectID": "feature_histogram.html#shared-interface-components",
    "href": "feature_histogram.html#shared-interface-components",
    "title": "14  Feature Histogram",
    "section": "",
    "text": "On the left, users can use the selection widgets to select the numerical feature to see the histogram/GMM distribution. Exactly one feature can be selected from all feature groups.\nOn the top right, users can use the filters to subset the data to find the groups of interest.\nBelow the filters, users can apply the visual channels widgets that allow users to Color by categorical features. Opacity by and Shape by are not supported because there are no points in the histogram/GMM plot.\nOn the bottom right, users can change the plot style using the plot styling widgets.",
    "crumbs": [
      "Univariate Analysis",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Feature Histogram</span>"
    ]
  },
  {
    "objectID": "feature_histogram.html#histogram-mode",
    "href": "feature_histogram.html#histogram-mode",
    "title": "14  Feature Histogram",
    "section": "14.2 Histogram Mode",
    "text": "14.2 Histogram Mode\nWith a single click, users can switch between the histogram mode and the Gaussian Mixture Model mode. When the checkbox is unchecked, the histogram mode is selected.\n\n\n\n\n\nHistogram mode plots a histogram of the selected numerical feature for each group. The histogram bin width is user-controllable, with default bin width determined automatically as the minimum bin width between the ‘sturges’ and ‘fd’ estimators (see here for more details). The maximum bin width is set to \\(1/3\\) the range of the data. The step size is set to \\(1/50\\) of the range.\n\n\n\n\n\nAdditionally, the skewness of the distribution is computed and displayed1.\nA rule of thumb categorization of skewness is as follows:\n\nStrongly left-skewed: &lt; -1\nModerately left-skewed: -1 to -0.5\nApproximately symmetric: -0.5 to -0.25 and 0.25 to 0.5\nAlmost symmetric: -0.25 to 0.25\nModerately right-skewed: 0.5 to 1\nStrongly right-skewed: &gt; 1\n\nHowever, the skewness is just one way to quantify the distribution shape. In the example above, the orange distribution was clearly bimodal, but the skewness alone could not capture this. In applications where the distribution is multi-modal, and each mode can represent certain subpopulations (e.g. a cell type, a cell state, a cell cycle phase, etc.), users can use the Gaussian Mixture Model mode to find subcomponents of each distribution in an unsupervised way.",
    "crumbs": [
      "Univariate Analysis",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Feature Histogram</span>"
    ]
  },
  {
    "objectID": "feature_histogram.html#gaussian-mixture-model-mode",
    "href": "feature_histogram.html#gaussian-mixture-model-mode",
    "title": "14  Feature Histogram",
    "section": "14.3 Gaussian Mixture Model Mode",
    "text": "14.3 Gaussian Mixture Model Mode\n\n\n\n\n\nA Gaussian Mixture Model (GMM) represents a dataset as a weighted sum of multiple Gaussian (normal) distributions, each defined by its own mean (\\(\\mu\\)) and (co)variance (\\(\\sigma^2\\)). By estimating the component parameters and their weights (mixing coefficients) from the data—commonly using the Expectation-Maximization (EM) algorithm—GMMs can capture complex, multimodal distributions that a single Gaussian cannot.\n\n14.3.1 Fit Gaussian Mixture Models\n\n\n\nGaussian Mixture Model Configuration\n\n\n\nSet “Max Components”: fit GMM on the selected numerical feature up to Max Components components, each of which has its component weights (\\(w_i\\)), means (\\(\\mu_i\\)) and variances (\\(\\sigma_i^2\\)).\nSet “Min Weight Threshold”: keep only the valid models that contain components that have at least Min Weight Threshold weights (the weights of all components add to 1)\nFLIM Playground will choose the valid model with the lowest BIC score that penalizes the model complexity to avoid overfitting\n\n\n\n14.3.2 Heterogeneity index\nTo quantify the subpopulation structure, based on the GMM fit, FLIM Playground computes an “H‑index” for each group as a weighted entropy‑distance: each component contributes according to its weight’s uncertainty (\\(-w_i \\log w_i\\))2 scaled by how far its mean \\(\\mu_i\\) sits from the overall mixture mean \\(\\bar\\mu = \\sum_{i=1}^k w_i\\,\\mu_i\\), normalized by the standard deviation of \\(\\mu_i\\)s.\n\\[\nH =\\sum_{i=1}^{k}\\bigl(-w_i \\log w_i\\bigr)\\,d_i, \\qquad d_i \\;=\\;\n\\frac{\\lvert\\mu_i - \\bar{\\mu}\\rvert}{\\sigma}\n\\]\n\n\n14.3.3 Classification\n\nUsers can choose to perform intersection thresholding or hard assignment to determine which GMM component each data point belongs to. It appends a new categorical feature column called GMM_Group (recognizable by methods in Data Analysis as a categorical feature) to the filtered dataset, the values of which are {color_group}_1, {color_group}_2, etc. In the example above, the color groups were created by 0.5hr and 4.5hr because the user colored the data by hour. The classification result can be saved by clicking:\n\n\n\n\n\n\n\nIntersection thresholding\n\nOnce the GMM is estimated, thresholds can be obtained by locating the intersection points of adjacent component densities: \\[\n                      w_1\\,\\mathcal{N}(x;\\mu_1,\\sigma_1^2)\n                      \\;=\\;\n                      w_2\\,\\mathcal{N}(x;\\mu_2,\\sigma_2^2)\n                      \\] where \\(w_1, \\mu_1, \\sigma_1\\) are the mixture weight, mean, and standard deviation of the first Gaussian component, respectively, and \\(w_2, \\mu_2, \\sigma_2\\) those of the second component.\nThe above equation can be formed as a quadratic equation and be solved for the unique root lying between \\(\\mu_1\\) and \\(\\mu_2\\). In practice, we bracket this interval and apply a robust one‐dimensional root-finding routine (e.g. Brent’s method) to compute intersection points. Data points are then assigned to the class corresponding to the interval in which they fall.\n\n\n\n\n\n\n\nImportant\n\n\n\nIn rare cases when there is more than one intersection point, the data point is assigned using hard assignment rather than intersection thresholding.\n\n\n\n\nHard assignment\n\nFor each data point, it computes the posterior probability (responsibility) of each component, and assigns the data point to the component with the highest responsibility.\n\n\\[\\text{label}(x) = \\arg\\max_{i} \\gamma_i(x)\\]\n\\[\\text{where} \\quad \\gamma_i(x) = \\frac{w_i \\; \\mathcal{N}\\bigl(x \\mid \\mu_i, \\sigma_i^2\\bigr)}{\\sum_{j=1}^K w_j \\; \\mathcal{N}\\bigl(x \\mid \\mu_j, \\sigma_j^2\\bigr)}\\]\n\n\n\n14.3.4 Example\nPham et al. used GMM with hard thresholding to create gates using NAD(P)H \\(a_1\\) and optical redox ratio. These gates were used to define metabolically stressed and fit cells in their study of the impact of cryopreservation on T cell metabolism.\n\n\n\n\n\n\n\nThey compared the GMM-derived gate with cell viability by Trypan blue staining:\n\n\n\n\n\nsuggesting that optical metabolic imaging (OMI) could serve as an early, non-destructive indicator of T cell viability post-thaw.\n\n\n\n\n1. Virtanen, P. et al. SciPy 1.0: Fundamental Algorithms for Scientific Computing in Python. Nature Methods 17, 261–272 (2020).\n\n\n2. Shannon, C. E. A mathematical theory of communication. The Bell System Technical Journal 27, 379–423 (1948).",
    "crumbs": [
      "Univariate Analysis",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Feature Histogram</span>"
    ]
  },
  {
    "objectID": "fov_comparison.html",
    "href": "fov_comparison.html",
    "title": "15  Field of View Comparison",
    "section": "",
    "text": "15.1 Shared Interface Components\nIn imaging datasets like FLIM data, field of view (FOV) is an important categorical feature that documents where a certain set of rows (e.g. cells) originates. Visualizing each FOV side by side on a numerical feature can help identify potential FOV-level outliers.\nFLIM Playground finds the FOV identifier column from the dataset using the FOV column name field in data analysis config (dataset not extracted by Data Extraction) or data extraction config (dataset extracted by Data Extraction).\nIf the FOV identifier column is not found in the dataset, then a warning message will be shown:\nIf found:\nBesides the shared components, this module does not have any method-specific components.",
    "crumbs": [
      "Univariate Analysis",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Field of View Comparison</span>"
    ]
  },
  {
    "objectID": "fov_comparison.html#shared-interface-components",
    "href": "fov_comparison.html#shared-interface-components",
    "title": "15  Field of View Comparison",
    "section": "",
    "text": "On the left, users can use the selection widgets to select the numerical feature to see the boxplot of each FOV. Exactly one feature can be selected from all feature groups.\nOn the top right, users can use the filters to subset the data to find the groups of interest.\nBelow the filters, users can apply the visual channels widgets that allows users to Color by categorical features. Opacity by and Shape by are not supported because there are no points in the boxplot.\nOn the bottom right, users can change the plot style using the plot styling widgets.",
    "crumbs": [
      "Univariate Analysis",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Field of View Comparison</span>"
    ]
  },
  {
    "objectID": "fov_comparison.html#example",
    "href": "fov_comparison.html#example",
    "title": "15  Field of View Comparison",
    "section": "15.2 Example",
    "text": "15.2 Example\nSometimes, the FOV-level boxplots may show consistent divergence across different imaging days, which may suggest the experimental or data extraction inconsistency (e.g. shifts are not optimized correctly for one day versus the others). Below is an example that, despite the same conditions, systematically diverged across days, but was consistent within the same day.",
    "crumbs": [
      "Univariate Analysis",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Field of View Comparison</span>"
    ]
  },
  {
    "objectID": "feature_distribution.html",
    "href": "feature_distribution.html",
    "title": "16  Feature Distribution",
    "section": "",
    "text": "16.1 Shared Interface Components\nThis method extends the univariate Feature Histogram method to visualize the distribution of two numerical features on a scatter plot. It helps reveal patterns such as correlations, clusters, trends, or outliers.",
    "crumbs": [
      "Bivariate Analysis",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Feature Distribution</span>"
    ]
  },
  {
    "objectID": "feature_distribution.html#shared-interface-components",
    "href": "feature_distribution.html#shared-interface-components",
    "title": "16  Feature Distribution",
    "section": "",
    "text": "On the left, users can use the selection widgets to select the two numerical features in the x-axis and y-axis.\nOn the top right, users can use the filters to subset the data to find the groups of interest.\nBelow the filters, users can apply the visual channels widgets that allow users to Color by, Opacity by, and Shape by categorical features.\nOn the bottom right, users can change the plot style using the plot styling widgets.",
    "crumbs": [
      "Bivariate Analysis",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Feature Distribution</span>"
    ]
  },
  {
    "objectID": "feature_distribution.html#marginal-distribution",
    "href": "feature_distribution.html#marginal-distribution",
    "title": "16  Feature Distribution",
    "section": "16.2 Marginal Distribution",
    "text": "16.2 Marginal Distribution\nMarginal distributions (distribution of a single feature) are plotted on the top and right of the scatter plot. Users can choose the plot type from the dropdown menu.\n\n\n\n\n\ngaussian fit: provides kernel-density estimate using Gaussian kernels. It uses gaussian_kde from scipy.stats and sets all parameters to default values.",
    "crumbs": [
      "Bivariate Analysis",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Feature Distribution</span>"
    ]
  },
  {
    "objectID": "feature_distribution.html#d-gaussian-mixture-model",
    "href": "feature_distribution.html#d-gaussian-mixture-model",
    "title": "16  Feature Distribution",
    "section": "16.3 2D Gaussian Mixture Model",
    "text": "16.3 2D Gaussian Mixture Model\nUsing the same method as fitting a 1D Gaussian Mixture Model, users can fit a 2D GMM by specifying Max Components and Min Weight Threshold on each color group.\nEllipses that capture approximately 95% of the points in each subcomponent are drawn. The color of the ellipses is determined by the color group that the subcomponent belongs to.\n\n\n\n\n\n\nNoteHow ellipses are drawn\n\n\n\n\n\nEach ellipse represents a subcomponent of the GMM.\n\nCenter of the ellipse is the mean of the subcomponent (\\(\\mu_x, \\mu_y\\)).\nThe ellipse is rotated by \\(\\theta = \\arctan2\\!\\left(v_{1y}, v_{1x} \\right)\\), where \\(\\mathbf{v}_1 = \\begin{bmatrix} v_{1x} \\\\ v_{1y} \\end{bmatrix}\\) is the first eigenvector of the covariance matrix, so that the major axis of the ellipse is aligned with the eigenvector corresponding to the largest eigenvalue.\nAxis lengths represent the variances along the major and minor axes of the ellipse. They are the eigenvalues of the covariance matrix scaled by \\(r = \\sqrt{\\chi^2_{\\,\\mathrm{df}=2,\\,p=0.95}}\\) (Mahalanobis distance) that captures approximately 95% of the points in the subcomponent.\n\n\n\n\nAll the components below will be rendered for each color group, which is created by user-chosen categorical features in Color by.\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nUsers can click on a legend group to hide/show the data points in that group. In the above example, to avoid cluttering the plot, the orange group is hidden.\n\n\nTables of subcomponents’ means, standard deviations, and weights are reported on the side.\n\n\n\n\n\nThe classification result can be saved by clicking:\n\n\n\n\n\nThe classification is done by hard assignment to determine which GMM component each data point belongs to. It appends a new categorical feature column called 2D_GMM_group to the filtered dataset, the values of which are {color_group}_group1, {color_group}_group2, etc. The downloaded dataset keeps all the features plus the new categorical feature column, which is recognized by any methods in Data Analysis as a categorical feature like others, and rows that pass the filters.",
    "crumbs": [
      "Bivariate Analysis",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Feature Distribution</span>"
    ]
  },
  {
    "objectID": "feature_distribution.html#regression-line",
    "href": "feature_distribution.html#regression-line",
    "title": "16  Feature Distribution",
    "section": "16.4 Regression line",
    "text": "16.4 Regression line\nA linear regression line is fitted to the data points in each color group. The key statistics are reported on the side.\n\n\n\n\n\n\\(R^{2}\\) tells how much of the variability in \\(y\\) is captured by the model, compared to just predicting the \\(\\bar{y}\\).\n\n\n\n\n\n\nNote\\(R^{2}\\)\n\n\n\n\n\n\n\\(R^{2} = 1\\) → perfect prediction.\n\\(R^{2} = 0\\) → model predicts no better than the mean.",
    "crumbs": [
      "Bivariate Analysis",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Feature Distribution</span>"
    ]
  },
  {
    "objectID": "phasor_analysis.html",
    "href": "phasor_analysis.html",
    "title": "17  Phasor Analysis",
    "section": "",
    "text": "17.1 Shared Interface Components\nThis method focuses on visualizing the distribution of the 1st harmonic or 2nd harmonic phasor coordinates, extracted by the Lifetime fit free extractor, and performs optional clustering to highlight subpopulations or structural patterns.",
    "crumbs": [
      "Bivariate Analysis",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Phasor Analysis</span>"
    ]
  },
  {
    "objectID": "phasor_analysis.html#shared-interface-components",
    "href": "phasor_analysis.html#shared-interface-components",
    "title": "17  Phasor Analysis",
    "section": "",
    "text": "On the top right, users can use the filters to subset the data to find the groups of interest.\nBelow the filters, users can apply the visual channels widgets that allow users to Color by, Opacity by, and Shape by categorical features.\nOn the bottom right, users can change the plot style using the plot styling widgets.",
    "crumbs": [
      "Bivariate Analysis",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Phasor Analysis</span>"
    ]
  },
  {
    "objectID": "phasor_analysis.html#select-phasor-coordinate",
    "href": "phasor_analysis.html#select-phasor-coordinate",
    "title": "17  Phasor Analysis",
    "section": "17.2 Select Phasor Coordinate",
    "text": "17.2 Select Phasor Coordinate\nInstead of using the bivariate selection widgets that select two generic numerical features, this method renders a dropdown menu to select the channel and another to select the harmonic.",
    "crumbs": [
      "Bivariate Analysis",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Phasor Analysis</span>"
    ]
  },
  {
    "objectID": "phasor_analysis.html#k-means-clustering",
    "href": "phasor_analysis.html#k-means-clustering",
    "title": "17  Phasor Analysis",
    "section": "17.3 K-means Clustering",
    "text": "17.3 K-means Clustering\nPhasor coordinates of single-cell ROIs from the selected channel and harmonic are plotted in the phasor space. K-means clustering can be performed for each color group (created by Color by). If Perform K-means Clustering is checked, users can specify the number of clusters to be created based on their prior knowledge. In the future, automatic tuning for this parameter, akin to selecting the number of components of GMM, using silhouette analysis will be added.\n\n\n\n\n\nK-means clustering is performed given the number of clusters specified for each color group. Mathematically, it is an iterative algorithm that finds the best cluster assignment: what cluster with what centroid each point belongs to. The best is defined as the one that minimizes the sum of the squared distances between each point and the center of the cluster it belongs to.\n\\[\n\\min_{\\{C_k\\}_{k=1}^K}\\;\\sum_{k=1}^K\\sum_{x_i\\in C_k}\\bigl\\lVert x_i-\\mu(C_k)\\bigr\\rVert_2^2,\n\\qquad\n\\mu(C_k)=\\frac{1}{|C_k|}\\sum_{x_i\\in C_k} x_i.\n\\]\nFirst, FLIM Playground standardizes the phasor coordinates because \\(g\\) (real part) and \\(s\\) (imaginary) are not necessarily on the same scale.\nThen, it performs k-means clustering using the sklearn.cluster.KMeans function. All the other hyperparameters control the optimization process (e.g. init controls the initialization of the centroids), and they are set to their default values. 42 is used as the random seed to ensure reproducibility.\nTo visualize the result of clustering, FLIM Playground draws a polygon (convex hull) that contains all the points of each cluster, the color of which is determined by the color group the cluster belongs to. It uses the scipy.spatial.ConvexHull function to calculate the convex hull. The center of each cluster is marked as a black bordered cross and users can hover over it to see its coordinates.\n\n\n\n\n\n\n17.3.1 Export Clustered Dataset\nUsers can download the clustered dataset by clicking:\n\n\n\n\n\nThe downloaded dataset keeps all the features plus the new categorical feature column (k_means_cluster), which is recognized by any method in Data Analysis as a categorical feature like others, and rows that pass the filters.",
    "crumbs": [
      "Bivariate Analysis",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Phasor Analysis</span>"
    ]
  },
  {
    "objectID": "dimension_reduction.html",
    "href": "dimension_reduction.html",
    "title": "18  Dimension Reduction",
    "section": "",
    "text": "18.1 Shared Interface Components\nTo represent and visualize high-dimensional data in a meaningful way and help users interpret the data, dimension reduction methods project the data into a lower-dimensional space. Three popular dimension reduction methods are often used: UMAP, PCA, and t-SNE.\nPrincipal Component Analysis (PCA) is a linear dimension reduction method that projects the data onto the directions of the largest variance. It is fast, deterministic, and easier to interpret (PCA loadings are provided), but it is limited by the linear nature of the projection. For a detailed discussion of PCA, please refer to this post.\nUniform Manifold Approximation and Projection (UMAP) and t-Distributed Stochastic Neighbor Embedding (t-SNE) are non-linear dimension reduction methods that can capture more complex patterns in the data. They are more flexible and can handle non-linear relationships between features, but they are more computationally expensive, less interpretable, not deterministic (FLIM Playground uses the random seed 42 to ensure reproducibility), and dependent on the hyperparameters. Here is a post that explains how UMAP and t-SNE work at a high level and the meaning of some of the hyperparameters.\nThe numerical features are standardized before the dimension reduction.",
    "crumbs": [
      "Multivariate Analysis",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Dimension Reduction</span>"
    ]
  },
  {
    "objectID": "dimension_reduction.html#shared-interface-components",
    "href": "dimension_reduction.html#shared-interface-components",
    "title": "18  Dimension Reduction",
    "section": "",
    "text": "On the left, users can use the selection widgets to select multiple numerical features from each feature group.\n\nOn the top right, users can use the filters to subset the data to find the groups of interest.\nBelow the filters, users can apply the visual channels widgets that allows users to Color by, Opacity by, and Shape by categorical features.\nOn the bottom right, users can change the plot style using the plot styling widgets.",
    "crumbs": [
      "Multivariate Analysis",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Dimension Reduction</span>"
    ]
  },
  {
    "objectID": "dimension_reduction.html#hyperparameter-widget",
    "href": "dimension_reduction.html#hyperparameter-widget",
    "title": "18  Dimension Reduction",
    "section": "18.2 Hyperparameter Widget",
    "text": "18.2 Hyperparameter Widget\nHyperparameters really matter. So we provide a set of interactive widgets to help users to change the hyperparameters and see their effects on the dimension reduction in real time.\n\n18.2.1 UMAP\nFLIM Playground uses the umap-learn implementation of UMAP. It chooses to expose n_neighbors and min_dist for users to tweak. Other hyperparameters are set to default values.\n\n\n18.2.2 t-SNE\nFLIM Playground uses the sklearn.manifold.TSNE implementation of t-SNE. It chooses to expose perplexity and early_exaggeration for users to tweak. Other hyperparameters are set to default values.",
    "crumbs": [
      "Multivariate Analysis",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Dimension Reduction</span>"
    ]
  },
  {
    "objectID": "classification.html",
    "href": "classification.html",
    "title": "19  Classification",
    "section": "",
    "text": "19.1 Shared Interface Components\nA machine learning classifier learns patterns from categorized data and then predicts the category of new, unseen data. This module provides a set of machine learning classifiers and interactive widgets to help users perform classification.\nAll the classifiers are implemented using scikit-learn and the performance metrics are calculated using sklearn.metrics. A fixed random seed (42) is used for all the classifiers to ensure reproducibility.\nThe performance metrics plots are cut off in the screenshot. See the performance metrics section for the complete view.",
    "crumbs": [
      "Multivariate Analysis",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Classification</span>"
    ]
  },
  {
    "objectID": "classification.html#shared-interface-components",
    "href": "classification.html#shared-interface-components",
    "title": "19  Classification",
    "section": "",
    "text": "On the left, users can use the selection widgets to select numerical features for the classifier. Multiple features can be selected from each feature group.\nOn the top right, users can use the filters to subset the data to find the groups of interest.\nAbove the performance metrics plots, users can change the plot style using the plot styling widgets.",
    "crumbs": [
      "Multivariate Analysis",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Classification</span>"
    ]
  },
  {
    "objectID": "classification.html#method-specific-components",
    "href": "classification.html#method-specific-components",
    "title": "19  Classification",
    "section": "19.2 Method-specific Components",
    "text": "19.2 Method-specific Components\n\nChoose the classifier and train-test split: the slider controls the proportion of the data used to train the classifier and the rest are used as unseen data to test its generalizability.\n\n\n\n\n\n\n\nClassify by: The Color by from the visual channels widgets is renamed to Classify by and it is used to form classes based on (combination of) selected categorical features. Other visual channels are not supported in this method.\n\n\n\n\n\n\n\nChoose the classes to be classified: classes are formed based on the combinations of categories of the selected categorical features. In general, it supports from binary classification to n-way classification where n is the number of classes. If one categorical feature is selected and after filtering has 3 categories, then all possible ways to classify are produced including the three-way classification. Additionally, the class x vs the rest option is provided for each class.\n\n\n\n\n\n\n\nSampling methods:\n\nNone: stratified random sampling of the data on classification classes, regardless of the class size. It is implemented using train_test_split from sklearn.model_selection.\nUndersampling: All classes are downsampled to the size of the smallest class. It is implemented using RandomUnderSampler from imbalanced-learn.\nOversampling: All classes are upsampled to the size of the largest class by randomly duplicating samples from minority classes. It is implemented using RandomOverSampler from imbalanced-learn.\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nFLIM Playground applies a unit normalization (i.e. z-score) to the features before training if the chosen classifier is SVM or Logistic Regression, because they are sensitive to feature magnitudes, while Random Forest and Gradient Boosting are not.\n\n\n\n19.2.1 Performance Metrics\nTo evaluate the performance of the classifiers, performance metrics visualizations are provided.\n\nConfusion Matrix\nFLIM Playground evaluates the trained classifier on the held-out test set and summarizes its predictions with sklearn.metrics.confusion_matrix. In the binary case, it is represented as:\n\n\n\n\n\n\n\n\n\nPredicted Positive\nPredicted Negative\n\n\n\n\nActual Positive\nTrue Positive (TP) – correct hits\nFalse Negative (FN) – missed positives\n\n\nActual Negative\nFalse Positive (FP) – false alarms\nTrue Negative (TN) – correct rejections\n\n\n\nOther metrics can be calculated based on the confusion matrix:\n\nAccuracy: \\(\\frac{TP + TN}{TP + FP + TN + FN}\\)\nPrecision: \\(\\frac{TP}{TP + FP}\\)\nRecall (Sensitivity): \\(\\frac{TP}{TP + FN}\\)\nF1 Score: \\(\\frac{2 \\times \\text{Precision} \\times \\text{Recall}}{\\text{Precision} + \\text{Recall}}\\)\n\n\n\n\n\n\n\n\nROC Curve\nAnother way to look at the performance of the classifier is to plot the Receiver Operating Characteristic (ROC) curve and its Area Under the Curve (AUC).\nA classifier usually outputs a score for each sample. To turn scores into hard labels a decision threshold must be chosen. Confusion matrix looks at the performance of the classifier at a single threshold (in the binary case, the threshold is 0.5), while ROC curve looks at the performance of the classifier at all thresholds (from 1 to 0).\nAt the origin (0, 0), the threshold is 1, so the classifier predicts all samples as negative, making the false positive rate \\(\\text{FPR} = \\frac{\\text{FP}}{\\text{FP} + \\text{TN}} = 0\\) and the true positive rate \\(\\text{TPR} = \\frac{\\text{TP}}{\\text{TP} + \\text{FN}} = 0\\), i.e. the origin. At the point (1, 1), the threshold is 0, so the classifier predicts all samples as positive, making the false positive rate 1 and the true positive rate 1, i.e. the point (1, 1).\nAUC summarizes the ROC curve by integrating it from 0 to 1, so it is threshold-free and has a nice interpretation: it is the probability that the classifier assigns a higher score to a randomly chosen positive sample \\(X^+\\) than to a randomly chosen negative sample \\(X^-\\).\nTo generalize to the \\(K\\)-class cases (\\(K &gt; 2\\)), FLIM Playground chooses the One-vs-Rest (OvR) strategy. For each class \\(i\\), it trains a binary classifier to predict the class \\(i\\) against all other classes. The ROC curve is then computed and plotted for each class.\n\n\n\n\n\n\n\nFeature Importance\nRandom Forest and Gradient Boosting classifiers provide feature importance scores.",
    "crumbs": [
      "Multivariate Analysis",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Classification</span>"
    ]
  }
]